{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f880c27-677b-46b0-9644-fc68d0f67528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005946f0-f957-44d1-833f-6b24c9207d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Apple GPU\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac6c9d10-944c-49bb-bced-b07c99133eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data's shape is (10000, 50, 110, 6) and Test Data's is (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "def getData(path):\n",
    "    train_file = np.load(path+\"/train.npz\")\n",
    "    train_data = train_file['data']\n",
    "    test_file = np.load(path+\"/test_input.npz\")\n",
    "    test_data = test_file['data']\n",
    "    print(f\"Training Data's shape is {train_data.shape} and Test Data's is {test_data.shape}\")\n",
    "    return train_data, test_data\n",
    "trainData, testData = getData(\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a8358d2-020a-453f-a6d0-cad96ed725c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowedNormalizedDataset(Dataset):\n",
    "    def __init__(self, data, scale=10.0):\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "        self.dt = 0.1  # Assuming fixed time step of 0.1 seconds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scene = self.data[idx].copy()\n",
    "        presence = (scene[..., 0] != 0) | (scene[..., 1] != 0)\n",
    "\n",
    "        origin = scene[0, 49].copy()\n",
    "        tx, ty, _, _, theta, _ = origin\n",
    "\n",
    "        cos_theta = np.cos(-theta)\n",
    "        sin_theta = np.sin(-theta)\n",
    "\n",
    "        # Increase feature dimension to 14 for new features\n",
    "\n",
    "        # --- Existing features (0-8) ---\n",
    "        # ... [Keep existing normalization code for positions, velocities, heading, etc.] ...\n",
    "        # normalized_scene[..., 0] to [..., 8] as original\n",
    "        normalized_scene = np.zeros((50, 110, 11), dtype=np.float32)\n",
    "\n",
    "        # --- Normalize positions ---\n",
    "        x = scene[..., 0] - tx\n",
    "        y = scene[..., 1] - ty\n",
    "        x_n = x * cos_theta - y * sin_theta\n",
    "        y_n = x * sin_theta + y * cos_theta\n",
    "        normalized_scene[..., 0] = x_n / self.scale\n",
    "        normalized_scene[..., 1] = y_n / self.scale\n",
    "\n",
    "        # --- Normalize velocities ---\n",
    "        vx = scene[..., 2]\n",
    "        vy = scene[..., 3]\n",
    "        vx_n = vx * cos_theta - vy * sin_theta\n",
    "        vy_n = vx * sin_theta + vy * cos_theta\n",
    "        normalized_scene[..., 2] = vx_n / self.scale\n",
    "        normalized_scene[..., 3] = vy_n / self.scale\n",
    "\n",
    "        # --- Heading normalization ---\n",
    "        heading = scene[..., 4]\n",
    "        normalized_heading = heading - theta\n",
    "        normalized_heading = (normalized_heading + np.pi) % (2 * np.pi) - np.pi\n",
    "        normalized_scene[..., 4] = normalized_heading\n",
    "\n",
    "        # --- agent_type (already encoded) ---\n",
    "        normalized_scene[..., 5] = scene[..., 5]  # agent_type\n",
    "\n",
    "        # --- Presence ---\n",
    "        normalized_scene[..., 6] = presence.astype(np.float32)\n",
    "\n",
    "   \n",
    "\n",
    "        # === New Feature 2: Speed ===\n",
    "        speed = np.sqrt(vx ** 2 + vy ** 2)\n",
    "        normalized_scene[..., 7] = speed / self.scale  # scale to keep consistent magnitude\n",
    "\n",
    "        # === New Feature 3: Distance to ego ===\n",
    "        ego_pos = scene[0, :, :2]  # (110, 2)\n",
    "        dist_to_ego = np.linalg.norm(scene[..., :2] - ego_pos[None, :, :], axis=-1)\n",
    "        normalized_scene[..., 8] = dist_to_ego / self.scale\n",
    "\n",
    "        # === New Feature 1: Minimum Distance to Any Agent (Dynamic Interaction) ===\n",
    "        positions = scene[..., :2]  # Original positions (50, 110, 2)\n",
    "\n",
    "        # === New Feature 2: Acceleration Magnitude (Motion Dynamics) ===\n",
    "        vx = scene[..., 2]\n",
    "        vy = scene[..., 3]\n",
    "        speed = np.sqrt(vx**2 + vy**2)\n",
    "        \n",
    "        # Compute acceleration (delta-v / delta-t)\n",
    "        accel = np.zeros_like(speed)\n",
    "        accel[:, 1:] = (speed[:, 1:] - speed[:, :-1]) / self.dt\n",
    "        accel[:, 0] = accel[:, 1]  # Handle first timestep\n",
    "        \n",
    "        normalized_scene[..., 9] = accel / (self.scale / self.dt)  # Feature index 10\n",
    "\n",
    "        # === New Feature 3: Time-to-Collision (TTC) with Ego (Critical Event Metric) ===\n",
    "        rel_speed = np.sqrt(\n",
    "            (vx - vx[0:1])**2 + \n",
    "            (vy - vy[0:1])**2\n",
    "        )\n",
    "        dist_to_ego = np.linalg.norm(\n",
    "            positions - positions[0:1], \n",
    "            axis=-1\n",
    "        )\n",
    "        \n",
    "        ttc = dist_to_ego / (rel_speed + 1e-5)  # Avoid division by zero\n",
    "        ttc = np.clip(ttc, 0, 10)  # Clip to meaningful range (0-10s)\n",
    "        normalized_scene[..., 10] = ttc / 10.0  # Feature index 11 (scaled 0-1)\n",
    "\n",
    "        # --- Masking ---\n",
    "        missing_mask = np.expand_dims(~presence, -1)\n",
    "        normalized_scene[..., :11] = np.where(missing_mask, 0, normalized_scene[..., :11])\n",
    "\n",
    "        # Inputs: first 50 timesteps\n",
    "        X = normalized_scene[:, :50, :]  # Now (50, 50, 14 features)\n",
    "\n",
    "        # Target: ego future positions and presence\n",
    "        ego_future = normalized_scene[0, 50:]\n",
    "        Y = np.zeros((60, 3), dtype=np.float32)\n",
    "        Y[:, :2] = ego_future[:, :2]\n",
    "        Y[:, 2] = ego_future[:, 6]  # presence\n",
    "\n",
    "        return (\n",
    "            torch.tensor(X, dtype=torch.float32),\n",
    "            torch.tensor(Y, dtype=torch.float32),\n",
    "            torch.tensor(origin, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81f6dee5-7d2e-471f-b58f-fd7556b08fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowedNormalizedTestDataset(Dataset):\n",
    "    def __init__(self, data, scale=10.0):\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "        self.dt = 0.1  # Assuming fixed time step of 0.1 seconds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scene = self.data[idx].copy()\n",
    "        presence = (scene[..., 0] != 0) | (scene[..., 1] != 0)\n",
    "\n",
    "        origin = scene[0, 49].copy()\n",
    "        tx, ty, _, _, theta, _ = origin\n",
    "\n",
    "        cos_theta = np.cos(-theta)\n",
    "        sin_theta = np.sin(-theta)\n",
    "\n",
    "        # Increase feature dimension to 14 for new features\n",
    "\n",
    "        # --- Existing features (0-8) ---\n",
    "        # ... [Keep existing normalization code for positions, velocities, heading, etc.] ...\n",
    "        # normalized_scene[..., 0] to [..., 8] as original\n",
    "        normalized_scene = np.zeros((50, 50, 11), dtype=np.float32)\n",
    "\n",
    "        # --- Normalize positions ---\n",
    "        x = scene[..., 0] - tx\n",
    "        y = scene[..., 1] - ty\n",
    "        x_n = x * cos_theta - y * sin_theta\n",
    "        y_n = x * sin_theta + y * cos_theta\n",
    "        normalized_scene[..., 0] = x_n / self.scale\n",
    "        normalized_scene[..., 1] = y_n / self.scale\n",
    "\n",
    "        # --- Normalize velocities ---\n",
    "        vx = scene[..., 2]\n",
    "        vy = scene[..., 3]\n",
    "        vx_n = vx * cos_theta - vy * sin_theta\n",
    "        vy_n = vx * sin_theta + vy * cos_theta\n",
    "        normalized_scene[..., 2] = vx_n / self.scale\n",
    "        normalized_scene[..., 3] = vy_n / self.scale\n",
    "\n",
    "        # --- Heading normalization ---\n",
    "        heading = scene[..., 4]\n",
    "        normalized_heading = heading - theta\n",
    "        normalized_heading = (normalized_heading + np.pi) % (2 * np.pi) - np.pi\n",
    "        normalized_scene[..., 4] = normalized_heading\n",
    "\n",
    "        # --- agent_type (already encoded) ---\n",
    "        normalized_scene[..., 5] = scene[..., 5]  # agent_type\n",
    "\n",
    "        # --- Presence ---\n",
    "        normalized_scene[..., 6] = presence.astype(np.float32)\n",
    "\n",
    "   \n",
    "\n",
    "        # === New Feature 2: Speed ===\n",
    "        speed = np.sqrt(vx ** 2 + vy ** 2)\n",
    "        normalized_scene[..., 7] = speed / self.scale  # scale to keep consistent magnitude\n",
    "\n",
    "        # === New Feature 3: Distance to ego ===\n",
    "        ego_pos = scene[0, :, :2]  # (110, 2)\n",
    "        dist_to_ego = np.linalg.norm(scene[..., :2] - ego_pos[None, :, :], axis=-1)\n",
    "        normalized_scene[..., 8] = dist_to_ego / self.scale\n",
    "\n",
    "        # === New Feature 1: Minimum Distance to Any Agent (Dynamic Interaction) ===\n",
    "        positions = scene[..., :2]  # Original positions (50, 110, 2)\n",
    "\n",
    "        # === New Feature 2: Acceleration Magnitude (Motion Dynamics) ===\n",
    "        vx = scene[..., 2]\n",
    "        vy = scene[..., 3]\n",
    "        speed = np.sqrt(vx**2 + vy**2)\n",
    "        \n",
    "        # Compute acceleration (delta-v / delta-t)\n",
    "        accel = np.zeros_like(speed)\n",
    "        accel[:, 1:] = (speed[:, 1:] - speed[:, :-1]) / self.dt\n",
    "        accel[:, 0] = accel[:, 1]  # Handle first timestep\n",
    "        \n",
    "        normalized_scene[..., 9] = accel / (self.scale / self.dt)  # Feature index 10\n",
    "\n",
    "        # === New Feature 3: Time-to-Collision (TTC) with Ego (Critical Event Metric) ===\n",
    "        rel_speed = np.sqrt(\n",
    "            (vx - vx[0:1])**2 + \n",
    "            (vy - vy[0:1])**2\n",
    "        )\n",
    "        dist_to_ego = np.linalg.norm(\n",
    "            positions - positions[0:1], \n",
    "            axis=-1\n",
    "        )\n",
    "        \n",
    "        ttc = dist_to_ego / (rel_speed + 1e-5)  # Avoid division by zero\n",
    "        ttc = np.clip(ttc, 0, 10)  # Clip to meaningful range (0-10s)\n",
    "        normalized_scene[..., 10] = ttc / 10.0  # Feature index 11 (scaled 0-1)\n",
    "\n",
    "        # --- Masking ---\n",
    "        missing_mask = np.expand_dims(~presence, -1)\n",
    "        normalized_scene[..., :11] = np.where(missing_mask, 0, normalized_scene[..., :11])\n",
    "\n",
    "        # Inputs: first 50 timesteps\n",
    "        X = normalized_scene[:, :50, :]  # Now (50, 50, 14 features)\n",
    "\n",
    "        # Target: ego future positions and presence\n",
    "        # ego_future = normalized_scene[0, 50:]\n",
    "        # Y = np.zeros((60, 3), dtype=np.float32)\n",
    "        # Y[:, :2] = ego_future[:, :2]\n",
    "        # Y[:, 2] = ego_future[:, 6]  # presence\n",
    "\n",
    "        return (\n",
    "            torch.tensor(X, dtype=torch.float32),\n",
    "            # torch.tensor(Y, dtype=torch.float32),\n",
    "            torch.tensor(origin, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a25669-bf13-4e59-aaf1-27a3b6246907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_ego_batch(predicted, origin, scale=10.0):\n",
    "    \"\"\"\n",
    "    Convert batch of normalized (and scaled) ego predictions back to global coordinates.\n",
    "\n",
    "    predicted: (B, ..., 2) tensor of normalized [x, y] positions\n",
    "    origin: (B, 6) tensor of ego's reference state at t=49\n",
    "    Returns:\n",
    "        (B, ..., 2) tensor of global [x, y] positions\n",
    "    \"\"\"\n",
    "    tx = origin[:, 0]  # (B,)\n",
    "    ty = origin[:, 1]  # (B,)\n",
    "    theta = origin[:, 4]  # (B,)\n",
    "\n",
    "    cos_theta = torch.cos(theta)\n",
    "    sin_theta = torch.sin(theta)\n",
    "\n",
    "    # Expand for broadcasting\n",
    "    while len(cos_theta.shape) < len(predicted.shape) - 1:\n",
    "        cos_theta = cos_theta.unsqueeze(1)\n",
    "        sin_theta = sin_theta.unsqueeze(1)\n",
    "        tx = tx.unsqueeze(1)\n",
    "        ty = ty.unsqueeze(1)\n",
    "\n",
    "    # Unscale before denormalizing\n",
    "    x = predicted[..., 0] * scale\n",
    "    y = predicted[..., 1] * scale\n",
    "\n",
    "    # Rotate\n",
    "    x_rot = x * cos_theta - y * sin_theta\n",
    "    y_rot = x * sin_theta + y * cos_theta\n",
    "\n",
    "    # Translate\n",
    "    x_global = x_rot + tx\n",
    "    y_global = y_rot + ty\n",
    "\n",
    "    return torch.stack([x_global, y_global], dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "443233d1-6760-46de-803a-526cb9540a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.16906469e+03,  1.68248551e+03,  5.46145515e+00, -5.85380650e+00,\n",
       "        -8.22467566e-01,  0.00000000e+00]),\n",
       " array([ 3.16959927e+03,  1.68191109e+03,  5.35655550e+00, -5.75120145e+00,\n",
       "        -8.22600550e-01,  0.00000000e+00]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData[1, 0, 49, :], trainData[1, 0, 50, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd96f5cb-6c4f-4d8e-9011-60dc615bc898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0000,  0.0000,  0.8006,  0.0019,  0.0000,  0.0000,  1.0000,  0.8006,\n",
       "          0.0000, -0.0057,  0.0000]),\n",
       " tensor([7.8468e-02, 9.1270e-05, 1.0000e+00]),\n",
       " torch.Size([6]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = WindowedNormalizedDataset(trainData)\n",
    "X, Y, origin = data.__getitem__(1)\n",
    "X[0, 49, :], Y[0, :], origin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f51bf65-dd08-4778-a8bb-e3fa981ea192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = denormalize_ego(Y[0, :2], origin)\n",
    "# x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff1569ab-c735-46e2-9c1d-4a61874ef9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 50, 50, 11])\n",
      "Output shape: torch.Size([1, 60, 2])\n",
      "\n",
      "Model parameters: 4,316,024\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TrajectoryTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=550, model_dim=256, num_heads=8, num_layers=3, dropout=0.1, pred_len=60, num_agents=50):\n",
    "        super().__init__()\n",
    "        self.model_dim = model_dim\n",
    "        self.pred_len = pred_len\n",
    "        self.num_agents = num_agents\n",
    "        \n",
    "        # Process each agent's full trajectory (50*7 = 350) into a single token\n",
    "        self.trajectory_encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, model_dim),\n",
    "            nn.LayerNorm(model_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(model_dim, model_dim),\n",
    "            nn.LayerNorm(model_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(model_dim, model_dim),\n",
    "            nn.LayerNorm(model_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 2-layer transformer encoder to process agent tokens\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=model_dim, \n",
    "                nhead=num_heads, \n",
    "                dropout=dropout, \n",
    "                batch_first=True\n",
    "            ),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        # Final linear layer to predict ego vehicle trajectory\n",
    "        self.output_fcpre = nn.Linear(model_dim, model_dim)  # 60*2 = 120\n",
    "        self.output_fc = nn.Linear(model_dim, pred_len * 2)  # 60*2 = 120\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, N, T, Ft = x.shape\n",
    "        \n",
    "        x = x.view(B, N, T * Ft)  # (B, 50, 350)\n",
    "        \n",
    "        # Encode each agent's trajectory into a token\n",
    "        agent_tokens = self.trajectory_encoder(x)  # (B, 50, model_dim)\n",
    "        \n",
    "        # Process all agent tokens through transformer\n",
    "        encoded_tokens = self.transformer_encoder(agent_tokens)  # (B, 50, model_dim)\n",
    "        \n",
    "        # Extract ego vehicle token (assuming agent 0 is ego)\n",
    "        ego_token = encoded_tokens[:, 0, :]  # (B, model_dim)\n",
    "        \n",
    "        # Predict ego trajectory\n",
    "        output = F.relu(self.output_fcpre(ego_token))  # (B, pred_len*2)\n",
    "\n",
    "        output = self.output_fc(output)  # (B, pred_len*2)\n",
    "        \n",
    "        # Reshape to (B, pred_len, 2)\n",
    "        output = output.view(B, self.pred_len, 2)  # (B, 60, 2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Test run\n",
    "model = TrajectoryTransformer()\n",
    "x = torch.randn(1, 50, 50, 11)  \n",
    "out = model(x)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {out.shape}\")  # Expected: (1, 60, 2)\n",
    "\n",
    "# Print model summary\n",
    "print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2aa753ec-b0a2-4151-92ed-cbcf6354b637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 4316024\n"
     ]
    }
   ],
   "source": [
    "model = TrajectoryTransformer().to(device=device)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f7683ce-9a52-4a67-9e3a-bfe7654a508d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (9000, 50, 110, 6)\n",
      "Validation shape: (1000, 50, 110, 6)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "num_samples = trainData.shape[0]\n",
    "indices = np.random.permutation(num_samples)\n",
    "split_index = int(0.9 * num_samples)\n",
    "train_idx, val_idx = indices[:split_index], indices[split_index:]\n",
    "\n",
    "# Split the data\n",
    "train_data = trainData[train_idx]\n",
    "val_data = trainData[val_idx]\n",
    "\n",
    "print(\"Train shape:\", train_data.shape)\n",
    "print(\"Validation shape:\", val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1575bca-4895-44db-9f5d-a28d867e37e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTensor = WindowedNormalizedDataset(train_data)\n",
    "testTensor = WindowedNormalizedDataset(val_data)\n",
    "train_dataloader = DataLoader(trainTensor, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(testTensor, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee46fc6c-294c-4b5f-bb3c-22140c2b205e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0363663626 | train val MSE 0.2993148610 | val MAE 8.5056570992 | val MSE 29.9314848185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/1000]: 100%|██████████| 71/71 [00:10<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0355911228 | train val MSE 0.3066141510 | val MAE 8.5933344364 | val MSE 30.6614166796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/1000]: 100%|██████████| 71/71 [00:10<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0353137321 | train val MSE 0.3181910166 | val MAE 8.9155746177 | val MSE 31.8191027641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0356508122 | train val MSE 0.3179093460 | val MAE 8.8289110363 | val MSE 31.7909404933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0355482517 | train val MSE 0.2914501568 | val MAE 8.2937741950 | val MSE 29.1450195312\n",
      " model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/1000]: 100%|██████████| 71/71 [00:10<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0353628136 | train val MSE 0.3056402083 | val MAE 8.6022416130 | val MSE 30.5640217364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/1000]: 100%|██████████| 71/71 [00:12<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0352213018 | train val MSE 0.3017595222 | val MAE 8.5078768581 | val MSE 30.1759525239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0348111402 | train val MSE 0.2995119533 | val MAE 8.5852371678 | val MSE 29.9511976838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0346334782 | train val MSE 0.3083590395 | val MAE 8.6567918137 | val MSE 30.8359042108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000]: 100%|██████████| 71/71 [00:12<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0348392787 | train val MSE 0.2834683596 | val MAE 8.1878931224 | val MSE 28.3468382657\n",
      " model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0347319633 | train val MSE 0.2832060119 | val MAE 8.2329675108 | val MSE 28.3206033111\n",
      " model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/1000]: 100%|██████████| 71/71 [00:12<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0342537747 | train val MSE 0.2828330088 | val MAE 8.2029586583 | val MSE 28.2832965702\n",
      " model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0339615774 | train val MSE 0.2992374685 | val MAE 8.6226542294 | val MSE 29.9237523079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0343547456 | train val MSE 0.2816727541 | val MAE 8.1696038321 | val MSE 28.1672762930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0338808886 | train val MSE 0.2890754966 | val MAE 8.3414170668 | val MSE 28.9075517356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/1000]: 100%|██████████| 71/71 [00:12<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0339795216 | train val MSE 0.2921801484 | val MAE 8.4588180929 | val MSE 29.2180186510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/1000]: 100%|██████████| 71/71 [00:11<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0342621264 | train val MSE 0.2968937408 | val MAE 8.5285064802 | val MSE 29.6893728375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0337239153 | train val MSE 0.2891243253 | val MAE 8.3824709579 | val MSE 28.9124333709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/1000]: 100%|██████████| 71/71 [00:11<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0338666899 | train val MSE 0.2766491999 | val MAE 8.2349732369 | val MSE 27.6649206579\n",
      " model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/1000]: 100%|██████████| 71/71 [00:11<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0333282986 | train val MSE 0.2920035579 | val MAE 8.3917291611 | val MSE 29.2003593445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0329030724 | train val MSE 0.2850941061 | val MAE 8.2999413237 | val MSE 28.5094122291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0324105481 | train val MSE 0.2931254082 | val MAE 8.4678928554 | val MSE 29.3125479221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/1000]: 100%|██████████| 71/71 [00:12<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0326384997 | train val MSE 0.2912029407 | val MAE 8.4354902580 | val MSE 29.1202941537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0328811422 | train val MSE 0.2861179714 | val MAE 8.3340475410 | val MSE 28.6117988527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0329098099 | train val MSE 0.2892209839 | val MAE 8.4160700515 | val MSE 28.9220949411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [26/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0326457202 | train val MSE 0.2885228305 | val MAE 8.4195875749 | val MSE 28.8522851169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0327373851 | train val MSE 0.2820426477 | val MAE 8.2171713859 | val MSE 28.2042659223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [28/1000]: 100%|██████████| 71/71 [00:11<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0324050306 | train val MSE 0.2862690894 | val MAE 8.3590280861 | val MSE 28.6269125342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0326822077 | train val MSE 0.2790043131 | val MAE 8.2048650160 | val MSE 27.9004306346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [30/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0323535281 | train val MSE 0.2802207805 | val MAE 8.2105493173 | val MSE 28.0220749080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [31/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0329379293 | train val MSE 0.2833156569 | val MAE 8.3205864206 | val MSE 28.3315714002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [32/1000]: 100%|██████████| 71/71 [00:11<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0325007069 | train val MSE 0.2902444259 | val MAE 8.4175126776 | val MSE 29.0244419277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [33/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0326967128 | train val MSE 0.2812104879 | val MAE 8.2078791112 | val MSE 28.1210543513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [34/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0327379474 | train val MSE 0.2811024419 | val MAE 8.1931152865 | val MSE 28.1102426797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [35/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0327264805 | train val MSE 0.2868835474 | val MAE 8.3488258570 | val MSE 28.6883509457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [36/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0327639994 | train val MSE 0.2820426661 | val MAE 8.2643693537 | val MSE 28.2042714804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [37/1000]: 100%|██████████| 71/71 [00:12<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0323746745 | train val MSE 0.2792671130 | val MAE 8.2111987546 | val MSE 27.9267181456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [38/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0322723504 | train val MSE 0.2750629410 | val MAE 8.1354736239 | val MSE 27.5062965304\n",
      " model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [39/1000]: 100%|██████████| 71/71 [00:12<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0323603787 | train val MSE 0.2792298405 | val MAE 8.2039263472 | val MSE 27.9229837060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [40/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0322436717 | train val MSE 0.2841915512 | val MAE 8.3086222336 | val MSE 28.4191598296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [41/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0323639852 | train val MSE 0.2784847710 | val MAE 8.2126293555 | val MSE 27.8484780043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [42/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0322382275 | train val MSE 0.2806014218 | val MAE 8.2324588075 | val MSE 28.0601461530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [43/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0321688225 | train val MSE 0.2748994366 | val MAE 8.1203929260 | val MSE 27.4899469018\n",
      " model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [44/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0322117830 | train val MSE 0.2775024443 | val MAE 8.1651412621 | val MSE 27.7502434999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [45/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0320304207 | train val MSE 0.2785166539 | val MAE 8.2001314983 | val MSE 27.8516690582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [46/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0319817208 | train val MSE 0.2794754733 | val MAE 8.2235475928 | val MSE 27.9475482106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [47/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0319414116 | train val MSE 0.2797660930 | val MAE 8.2409902960 | val MSE 27.9766107202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [48/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0320921741 | train val MSE 0.2791983068 | val MAE 8.2141249925 | val MSE 27.9198355526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [49/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0319138324 | train val MSE 0.2777206521 | val MAE 8.1821963415 | val MSE 27.7720653117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [50/1000]: 100%|██████████| 71/71 [00:12<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0320993720 | train val MSE 0.2766401854 | val MAE 8.1619031429 | val MSE 27.6640230119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [51/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0322310538 | train val MSE 0.2758614433 | val MAE 8.1460059807 | val MSE 27.5861451030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [52/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0319890266 | train val MSE 0.2750735434 | val MAE 8.1475604549 | val MSE 27.5073563755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [53/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0321807451 | train val MSE 0.2769393425 | val MAE 8.1871334761 | val MSE 27.6939380169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [54/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0320024965 | train val MSE 0.2794148696 | val MAE 8.2378481627 | val MSE 27.9414917827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [55/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0319695060 | train val MSE 0.2779243996 | val MAE 8.1963479444 | val MSE 27.7924432755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [56/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0320465534 | train val MSE 0.2798280818 | val MAE 8.2377507463 | val MSE 27.9828129411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [57/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0322190532 | train val MSE 0.2766850521 | val MAE 8.1777058691 | val MSE 27.6685077995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [58/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0317630850 | train val MSE 0.2749145031 | val MAE 8.1412269175 | val MSE 27.4914538413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [59/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0323052118 | train val MSE 0.2734348131 | val MAE 8.1105476171 | val MSE 27.3434905708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [60/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0321820414 | train val MSE 0.2796047698 | val MAE 8.2486709356 | val MSE 27.9604786336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [61/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0319001500 | train val MSE 0.2781606433 | val MAE 8.2091451436 | val MSE 27.8160636723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [62/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0321680340 | train val MSE 0.2767249313 | val MAE 8.1852679029 | val MSE 27.6724915802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [63/1000]: 100%|██████████| 71/71 [00:11<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0316717533 | train val MSE 0.2763777815 | val MAE 8.1737418994 | val MSE 27.6377772391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [64/1000]: 100%|██████████| 71/71 [00:11<00:00,  5.94it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     62\u001b[39m unnorm_true = denormalize_ego_batch(batchY, origin)\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# print(pred[..., :2].shape, batchY[..., :2].shape, origin.shape, unnorm_pred.shape)\u001b[39;00m\n\u001b[32m     65\u001b[39m \n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# break\u001b[39;00m\n\u001b[32m     67\u001b[39m \n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# unnorm_pred = denormalize_ego(pred[..., :2], origin)\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# unnorm_true = denormalize_ego(batchY, origin)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m val_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m val_mae += nn.L1Loss()(unnorm_pred[..., :\u001b[32m2\u001b[39m], unnorm_true[..., :\u001b[32m2\u001b[39m]).item()\n\u001b[32m     74\u001b[39m val_mse += nn.MSELoss()(unnorm_pred[..., :\u001b[32m2\u001b[39m], unnorm_true[..., :\u001b[32m2\u001b[39m]).item()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#  train MSE 0.0019108728 | train val MSE 0.0105765359 | val MAE 1.9288981240 | val MSE 1.0576545876\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#  train MSE 0.0356432942 | train val MSE 0.3016946956 | val MAE 8.4936904013 | val MSE 30.1694715023\n",
    "\n",
    "\n",
    "best_model = torch.load(\"./models/modelI/best_model.pt\", map_location=torch.device('cpu'))\n",
    "model.load_state_dict(best_model)\n",
    "\n",
    "epochs = 1000\n",
    "lossFn = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-6)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.25)\n",
    "best_val_loss = 0.3016946956 # float('inf')\n",
    "best_train_loss = 0.0356432942 #float('inf')\n",
    "position_scale = 1.0\n",
    "velocity_scale = 1.0\n",
    "all_losses = {\n",
    "    'training_mse_loss':[],\n",
    "    'validation_mse_loss':[],\n",
    "    'true_mse':[],\n",
    "    'true_mae':[]\n",
    "}\n",
    "\n",
    "for each_epoch in range(epochs):\n",
    "    model.train()\n",
    "    runningLoss = 0.0\n",
    "    loop = tqdm(train_dataloader, desc=f\"Epoch [{each_epoch+1}/{epochs}]\")\n",
    "    \n",
    "    for batchX, batchY, origin in loop:\n",
    "        batchX = batchX.to(device)\n",
    "        batchY = batchY.to(device)\n",
    "        origin = origin.to(device)\n",
    "\n",
    "        \n",
    "        pred = model(batchX)  # pred shape: (B, 60, 2)\n",
    "        \n",
    "        loss = lossFn(pred[..., :2], batchY[..., :2]).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.item()        \n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_mae = 0\n",
    "    val_mse = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batchX, batchY, origin in loop:\n",
    "            batchX = batchX.to(device)\n",
    "            batchY = batchY.to(device)\n",
    "            origin = origin.to(device)\n",
    "\n",
    "            \n",
    "            pred = model(batchX)  # pred shape: (B, 60, 2)\n",
    "            \n",
    "            loss = lossFn(pred[..., :2], batchY[..., :2]).to(device)\n",
    "            unnorm_pred = denormalize_ego_batch(pred, origin)\n",
    "            unnorm_true = denormalize_ego_batch(batchY, origin)\n",
    "\n",
    "            # print(pred[..., :2].shape, batchY[..., :2].shape, origin.shape, unnorm_pred.shape)\n",
    "            \n",
    "            # break\n",
    "            \n",
    "            # unnorm_pred = denormalize_ego(pred[..., :2], origin)\n",
    "            # unnorm_true = denormalize_ego(batchY, origin)\n",
    "\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_mae += nn.L1Loss()(unnorm_pred[..., :2], unnorm_true[..., :2]).item()\n",
    "            val_mse += nn.MSELoss()(unnorm_pred[..., :2], unnorm_true[..., :2]).item()\n",
    "    # break\n",
    "    train_loss = runningLoss/len(train_dataloader)\n",
    "    val_loss /= len(val_dataloader)\n",
    "    val_mae /= len(val_dataloader)\n",
    "    val_mse /= len(val_dataloader)\n",
    "    \n",
    "    all_losses[\"training_mse_loss\"].append(train_loss)\n",
    "    all_losses[\"validation_mse_loss\"].append(val_loss)\n",
    "    all_losses[\"true_mse\"].append(val_mse)\n",
    "    all_losses[\"true_mae\"].append(val_mae)\n",
    "    \n",
    "    loop.write(f\" train MSE {train_loss:.10f} | train val MSE {val_loss:.10f} | val MAE {val_mae:.10f} | val MSE {val_mse:.10f}\")\n",
    "    scheduler.step()\n",
    "    \n",
    "    if train_loss < best_train_loss and val_loss < best_val_loss :#- 1e-3\n",
    "        best_val_loss = val_loss\n",
    "        best_train_loss = train_loss\n",
    "        no_improvement = 0\n",
    "        torch.save(model.state_dict(), \"./models/modelI/best_model.pt\")\n",
    "        loop.write(f\" model Saved\")\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "228c9a60-f253-40d5-a2b8-4333d5eb0fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = WindowedNormalizedTestDataset(testData)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "\n",
    "best_model = torch.load(\"./models/modelI/best_model.pt\")\n",
    "model = model = TrajectoryTransformer().to(device=device)\n",
    "# model = model = TrajectoryTransformerPlus().to(device=device)\n",
    "\n",
    "\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "pred_list = []\n",
    "with torch.no_grad():\n",
    "    for batchX, origin in test_loader:\n",
    "        batchX = batchX.to(device)\n",
    "        batchY = batchY.to(device)\n",
    "        origin = origin.to(device)\n",
    "\n",
    "        \n",
    "        pred = model(batchX)  # pred shape: (B, 60, 2)\n",
    "        \n",
    "        unnorm_pred = denormalize_ego_batch(pred[..., :2], origin)\n",
    "        # print(unnorm_pred.shape)\n",
    "        pred_list.append(unnorm_pred.cpu().numpy())\n",
    "        # print(len(pred))\n",
    "        \n",
    "\n",
    "pred_list = np.concatenate(pred_list, axis=0)  \n",
    "pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n",
    "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
    "output_df.index.name = 'index'\n",
    "output_df.to_csv('./models/modelI/testTransFormer.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f02244-c098-4112-9db2-8ab1cb03afdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train MSE 0.0067906785 | train val MSE 0.0365855057 | val MAE 3.3914739154 | val MSE 3.6585507989 -- Test 8.03946\n",
    "# train MSE 0.0043151287 | train val MSE 0.0219720890 | val MAE 2.6549732704 | val MSE 2.1972093526 -- Test 7.62\n",
    "# train MSE 0.0037161494 | train val MSE 0.0218982005 | val MAE 2.6644983813 | val MSE 2.1898213290 -- Test 7.69\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
