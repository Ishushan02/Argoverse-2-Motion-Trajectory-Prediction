{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d3b115a-8a6f-4d8d-b59a-d847eea34e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data, Batch\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93101e16-8233-406e-8406-3495b2d5625d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Silicon GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using Apple Silicon GPU\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7582d75c-6f35-45a3-88ee-387796d6536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(path):\n",
    "    train_file = np.load(path+\"/train.npz\")\n",
    "    train_data = train_file['data']\n",
    "    test_file = np.load(path+\"/test_input.npz\")\n",
    "    test_data = test_file['data']\n",
    "    print(f\"Training Data's shape is {train_data.shape} and Test Data's is {test_data.shape}\")\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca028df6-fc7f-4192-b1ea-9c0b93d1cbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data's shape is (10000, 50, 110, 6) and Test Data's is (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "trainData, testData = getData(\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31356c59-fc2a-4fca-ab46-bebdc0768d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class WindowedNormalizedDataset(Dataset):\n",
    "    def __init__(self, data, window_size, forecast_horizon):\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "\n",
    "        self.indices = []\n",
    "        for sample in range(data.shape[0]):\n",
    "            for t in range(data.shape[2] - window_size - forecast_horizon + 1):\n",
    "                self.indices.append((sample, t))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_idx, t = self.indices[idx]\n",
    "\n",
    "        origin = self.data[sample_idx, 0, 49, :2].copy()\n",
    "        x = self.data[sample_idx, :, t:t+self.window_size, :]\n",
    "        x[..., :2] -= origin\n",
    "\n",
    "        x[..., :4] = x[..., :4] / 10\n",
    "        y = self.data[sample_idx, 0, t+self.window_size:t+self.window_size+self.forecast_horizon, :2]\n",
    "        y = y/10\n",
    "        # print(x.shape, y.shape)\n",
    "\n",
    "        return (\n",
    "        torch.tensor(x, dtype=torch.float32),\n",
    "        torch.tensor(y, dtype=torch.float32),\n",
    "        torch.tensor(origin, dtype=torch.float32)  # normalize origin for consistency\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d3a04b-1e3e-48c5-8bbb-e95da634a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "# np.random.seed(42)\n",
    "\n",
    "scale = 9.0\n",
    "\n",
    "N = trainData.shape[0]\n",
    "val_size = int(0.1 * N)\n",
    "train_size = N - val_size\n",
    "\n",
    "train_dataset = WindowedNormalizedDataset(data = trainData[:train_size], window_size=50, forecast_horizon=60)\n",
    "validation_dataset = WindowedNormalizedDataset(data = trainData[train_size:], window_size=50, forecast_horizon=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e85cd25e-3e22-4b47-a557-9d56c9dc1713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 1359906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoderModel(\n",
       "  (layer1): Linear(in_features=6, out_features=32, bias=True)\n",
       "  (layer2): Linear(in_features=32, out_features=64, bias=True)\n",
       "  (layer3): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (encoderlstm): LSTM(128, 256, num_layers=2, batch_first=True, dropout=0.3)\n",
       "  (pool): AdaptiveAvgPool1d(output_size=60)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (decoderlstm): LSTM(256, 128, num_layers=2, batch_first=True, dropout=0.3)\n",
       "  (layer10): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (layer11): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (layer12): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (skip1): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (skip2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (skip3): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (skip4): Linear(in_features=256, out_features=256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderDecoderModel(nn.Module):\n",
    "    def __init__(self, infeatures, outfeatures=2):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.layer1 = nn.Linear(infeatures, 32)\n",
    "        self.layer2 = nn.Linear(32, 64)\n",
    "        self.layer3 = nn.Linear(64, 128)\n",
    "        self.encoderlstm = nn.LSTM(128, 256, num_layers=2, batch_first=True, dropout=0.3)\n",
    "        \n",
    "        # Changed pooling target from 20 to 60\n",
    "        self.pool = nn.AdaptiveAvgPool1d(60)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoderlstm = nn.LSTM(256, 128, num_layers=2, batch_first=True, dropout=0.3)\n",
    "        self.layer10 = nn.Linear(128, 64)\n",
    "        self.layer11 = nn.Linear(64, 32)\n",
    "        self.layer12 = nn.Linear(32, outfeatures)\n",
    "        \n",
    "        # Skip connections\n",
    "        self.skip1 = nn.Linear(32, 32)\n",
    "        self.skip2 = nn.Linear(64, 64)\n",
    "        self.skip3 = nn.Linear(128, 128)\n",
    "        self.skip4 = nn.Linear(256, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        \n",
    "        # Encoder\n",
    "        out1 = nn.ReLU()(self.layer1(x))\n",
    "        out2 = nn.ReLU()(self.layer2(out1))\n",
    "        out3 = nn.ReLU()(self.layer3(out2))\n",
    "        \n",
    "        # LSTM processing\n",
    "        tempout3 = out3.view(batch_size, -1, out3.size(-1))\n",
    "        out4, _ = self.encoderlstm(tempout3)\n",
    "        \n",
    "        # Changed pooling to 60\n",
    "        tempout4 = self.pool(out4.permute(0, 2, 1))\n",
    "        tempout4 = tempout4.permute(0, 2, 1)\n",
    "        lstmskip = tempout4 + self.skip4(tempout4)\n",
    "        \n",
    "        # Decoder LSTM\n",
    "        out5, _ = self.decoderlstm(lstmskip)\n",
    "        \n",
    "        out3_reduced = F.adaptive_avg_pool2d(out3.permute(0, 3, 1, 2), (60, 1)).squeeze(-1).permute(0, 2, 1)\n",
    "        mlpskip1 = out3_reduced + self.skip3(out5)\n",
    "        out6 = nn.ReLU()(self.layer10(mlpskip1))\n",
    "        \n",
    "        out2_reduced = F.adaptive_avg_pool2d(out2.permute(0, 3, 1, 2), (60, 1)).squeeze(-1).permute(0, 2, 1)\n",
    "        mlpskip2 = out2_reduced + self.skip2(out6)\n",
    "        out7 = nn.ReLU()(self.layer11(mlpskip2))\n",
    "        \n",
    "        out1_reduced = F.adaptive_avg_pool2d(out1.permute(0, 3, 1, 2), (60, 1)).squeeze(-1).permute(0, 2, 1)\n",
    "        mlpskip3 = out1_reduced + self.skip1(out7)\n",
    "        out8 = self.layer12(mlpskip3)\n",
    "        \n",
    "        return out8\n",
    "\n",
    "# Verify the output shape\n",
    "def xavier_init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "model = EncoderDecoderModel(6, 2)\n",
    "model.apply(xavier_init_weights)\n",
    "\n",
    "# test = torch.randn(128, 50, 50, 6)\n",
    "# out = model(test)\n",
    "# print(out.shape)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3dcfd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 60, 2])\n",
      "Total parameters: 1290350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoderModel(\n",
       "  (project_layer): Linear(in_features=2500, out_features=60, bias=True)\n",
       "  (layer1): Linear(in_features=6, out_features=32, bias=True)\n",
       "  (layer2): Linear(in_features=32, out_features=64, bias=True)\n",
       "  (layer3): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (encoder_lstm): LSTM(128, 256, num_layers=2, batch_first=True)\n",
       "  (decoder_lstm): LSTM(256, 128, batch_first=True)\n",
       "  (layer10): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (layer11): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (layer12): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EncoderDecoderModel(nn.Module):\n",
    "    def __init__(self, infeatures = 6, outfeatures=2, agents = 50, timestamp = 50, windowSize = 60, ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # batch_size, x_dim, y_dim, features = x.shape\n",
    "\n",
    "        # x = x.view(batch_size, x_dim * y_dim, features)\n",
    "        self.project_layer = nn.Linear(agents * timestamp, 60)  \n",
    "        # MLP Encoder\n",
    "        self.layer1 = nn.Linear(infeatures, 32)\n",
    "        self.layer2 = nn.Linear(32, 64)\n",
    "        self.layer3 = nn.Linear(64, 128)\n",
    "        \n",
    "        # LSTM Encoder (2 layers)\n",
    "        self.encoder_lstm = nn.LSTM(128, 256, num_layers=2, batch_first=True)\n",
    "        \n",
    "        # Decoder LSTM (1 layer)\n",
    "        self.decoder_lstm = nn.LSTM(256, 128, num_layers=1, batch_first=True)\n",
    "        \n",
    "        # MLP Decoder\n",
    "        self.layer10 = nn.Linear(128, 64)\n",
    "        self.layer11 = nn.Linear(64, 32)\n",
    "        self.layer12 = nn.Linear(32, outfeatures)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len, infeatures]\n",
    "        batch_size, x_dim, y_dim, features = x.shape\n",
    "\n",
    "        x = x.view(batch_size, x_dim * y_dim, features)\n",
    "        # project = self.project_layer(x_dim * y_dim, 60)  # maps x*y → 60\n",
    "        x = x.permute(0, 2, 1)  # (batch, features, x*y)\n",
    "        x = self.project_layer(x)          # (batch, features, 60)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        x = F.relu(self.layer1(x))\n",
    "        \n",
    "        \n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        \n",
    "        # # LSTM Encoder\n",
    "        # print(out.shape)\n",
    "        x, _ = self.encoder_lstm(x)\n",
    "        # print(x.shape)\n",
    "        \n",
    "        # # LSTM Decoder\n",
    "        x, _ = self.decoder_lstm(x)\n",
    "        # print(x.shape)\n",
    "        \n",
    "        # # Decoder MLP\n",
    "        x = F.relu(self.layer10(x))\n",
    "        x = F.relu(self.layer11(x))\n",
    "        x = self.layer12(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Weight initialization\n",
    "def xavier_init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "model = EncoderDecoderModel(6, 2)\n",
    "model.apply(xavier_init_weights)\n",
    "\n",
    "test = torch.randn(128, 50, 50, 6)\n",
    "out = model(test)\n",
    "print(out.shape)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcbeccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 60, 2])\n",
      "Total parameters: 2191698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoderModel(\n",
       "  (conv1d): Conv1d(6, 64, kernel_size=(3,), stride=(42,), padding=(1,))\n",
       "  (layer1): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (layer2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (encoder_lstm): LSTM(256, 256, num_layers=2, batch_first=True)\n",
       "  (decoder_lstm): LSTM(256, 256, num_layers=2, batch_first=True)\n",
       "  (layer10): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (layer11): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (layer12): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (layer13): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (layer14): Linear(in_features=16, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EncoderDecoderModel(nn.Module):\n",
    "    def __init__(self, infeatures=6, outfeatures=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1d = nn.Conv1d(in_channels=infeatures, out_channels=64, kernel_size=3, stride=42, padding=1)\n",
    "\n",
    "        self.layer1 = nn.Linear(64, 128)\n",
    "        self.layer2 = nn.Linear(128, 256)\n",
    "\n",
    "        self.encoder_lstm = nn.LSTM(256, 256, num_layers=2, batch_first=True)\n",
    "\n",
    "        self.decoder_lstm = nn.LSTM(256, 256, num_layers=2, batch_first=True)\n",
    "\n",
    "        self.layer10 = nn.Linear(256, 128)\n",
    "        self.layer11 = nn.Linear(128, 64)\n",
    "        self.layer12 = nn.Linear(64, 32)\n",
    "        self.layer13 = nn.Linear(32, 16)\n",
    "        self.layer14 = nn.Linear(16, outfeatures)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, x_dim, y_dim, features = x.shape\n",
    "\n",
    "        x = x.permute(0, 3, 1, 2).reshape(batch_size, features, -1)  # (batch, infeatures, 2500)\n",
    "\n",
    "        x = self.conv1d(x)  # (batch, 64, 60)\n",
    "        x = x.permute(0, 2, 1)  # (batch, 60, 64)\n",
    "\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x, _ = self.encoder_lstm(x)\n",
    "        x, _ = self.decoder_lstm(x)\n",
    "\n",
    "        x = F.relu(self.layer10(x))\n",
    "        x = F.relu(self.layer11(x))\n",
    "        x = F.relu(self.layer12(x))\n",
    "        x = F.relu(self.layer13(x))\n",
    "        x = self.layer14(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = EncoderDecoderModel(6, 2)\n",
    "model.apply(xavier_init_weights)\n",
    "\n",
    "test = torch.randn(128, 50, 50, 6)\n",
    "out = model(test)\n",
    "print(out.shape)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e37b2cc1-9feb-4687-96c6-43bf243de04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000]:   0%|          | 0/71 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000]: 100%|██████████| 71/71 [00:20<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 113979.82394366198,  Validation Loss:107880.9609375 , Absolute MSE:10788096.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 108308.75704225352,  Validation Loss:100067.1298828125 , Absolute MSE:10006713.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Training Loss: 100618.72722271127,  Validation Loss:93249.8642578125 , Absolute MSE:9324986.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Training Loss: 94988.40713028169,  Validation Loss:87671.3408203125 , Absolute MSE:8767133.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Training Loss: 89961.58263644367,  Validation Loss:83286.0673828125 , Absolute MSE:8328607.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/1000]: 100%|██████████| 71/71 [00:17<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Training Loss: 85756.82873019367,  Validation Loss:78690.6435546875 , Absolute MSE:7869063.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Training Loss: 80907.42143485915,  Validation Loss:73530.22119140625 , Absolute MSE:7353022.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Training Loss: 76255.72001540494,  Validation Loss:69428.7470703125 , Absolute MSE:6942874.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Training Loss: 73356.95004401408,  Validation Loss:67583.72998046875 , Absolute MSE:6758373.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training Loss: 72644.20290492958,  Validation Loss:67145.24853515625 , Absolute MSE:6714524.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/1000]: 100%|██████████| 71/71 [00:17<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Training Loss: 72206.41428257042,  Validation Loss:67061.84033203125 , Absolute MSE:6706183.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Training Loss: 72206.51430457746,  Validation Loss:67075.79541015625 , Absolute MSE:6707579.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Training Loss: 72200.87918133802,  Validation Loss:67042.1845703125 , Absolute MSE:6704218.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Training Loss: 72271.32482394367,  Validation Loss:67053.44189453125 , Absolute MSE:6705344.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Training Loss: 72147.2745378521,  Validation Loss:67061.30419921875 , Absolute MSE:6706130.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/1000]: 100%|██████████| 71/71 [00:17<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Training Loss: 72203.83351672535,  Validation Loss:67111.72802734375 , Absolute MSE:6711173.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Training Loss: 72091.45163952465,  Validation Loss:67062.56689453125 , Absolute MSE:6706256.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Training Loss: 72071.25990316902,  Validation Loss:67065.90234375 , Absolute MSE:6706590.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Training Loss: 72273.93788512323,  Validation Loss:67055.3466796875 , Absolute MSE:6705534.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Training Loss: 72486.12758582746,  Validation Loss:67055.03564453125 , Absolute MSE:6705503.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/1000]: 100%|██████████| 71/71 [00:17<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Training Loss: 72307.88083186619,  Validation Loss:67064.70654296875 , Absolute MSE:6706470.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Training Loss: 72398.61014524648,  Validation Loss:67064.24462890625 , Absolute MSE:6706424.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Training Loss: 72065.56629621479,  Validation Loss:67063.3623046875 , Absolute MSE:6706336.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/1000]: 100%|██████████| 71/71 [00:16<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Training Loss: 72180.45092429577,  Validation Loss:67042.35546875 , Absolute MSE:6704235.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Training Loss: 72417.39012984154,  Validation Loss:67055.72998046875 , Absolute MSE:6705573.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [26/1000]: 100%|██████████| 71/71 [00:17<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Training Loss: 72365.27695862677,  Validation Loss:67055.68408203125 , Absolute MSE:6705568.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Training Loss: 72159.5303147007,  Validation Loss:67055.0595703125 , Absolute MSE:6705506.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [28/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Training Loss: 72060.25357614437,  Validation Loss:67056.87744140625 , Absolute MSE:6705687.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Training Loss: 72387.36944322183,  Validation Loss:67097.7421875 , Absolute MSE:6709774.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [30/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Training Loss: 71980.1785871479,  Validation Loss:67063.005859375 , Absolute MSE:6706300.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [31/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Training Loss: 72206.13099691902,  Validation Loss:67081.72265625 , Absolute MSE:6708171.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [32/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Training Loss: 71998.43915052817,  Validation Loss:67043.86279296875 , Absolute MSE:6704386.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [33/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Training Loss: 72287.98492517606,  Validation Loss:67038.86572265625 , Absolute MSE:6703886.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [34/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Training Loss: 72182.83901848592,  Validation Loss:67088.3876953125 , Absolute MSE:6708838.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [35/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Training Loss: 72107.96033230633,  Validation Loss:67045.21337890625 , Absolute MSE:6704521.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [36/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Training Loss: 72162.80100132042,  Validation Loss:67059.62109375 , Absolute MSE:6705962.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [37/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Training Loss: 72171.25830765846,  Validation Loss:67040.26904296875 , Absolute MSE:6704027.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [38/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Training Loss: 72289.4793683979,  Validation Loss:67047.8291015625 , Absolute MSE:6704783.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [39/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Training Loss: 72322.9776078345,  Validation Loss:67040.46142578125 , Absolute MSE:6704046.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [40/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Training Loss: 72335.60497359154,  Validation Loss:67064.265625 , Absolute MSE:6706426.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [41/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Training Loss: 72110.57878521127,  Validation Loss:67065.1474609375 , Absolute MSE:6706515.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [42/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Training Loss: 71980.48228433098,  Validation Loss:67041.88671875 , Absolute MSE:6704188.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [43/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Training Loss: 72600.58582746479,  Validation Loss:67043.50048828125 , Absolute MSE:6704350.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [44/1000]: 100%|██████████| 71/71 [00:17<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Training Loss: 72402.88853433098,  Validation Loss:67043.7587890625 , Absolute MSE:6704376.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [45/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Training Loss: 72301.66186179577,  Validation Loss:67055.6474609375 , Absolute MSE:6705565.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [46/1000]: 100%|██████████| 71/71 [00:17<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Training Loss: 72091.08285651408,  Validation Loss:67050.4052734375 , Absolute MSE:6705040.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [47/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Training Loss: 72142.53273547535,  Validation Loss:67072.0849609375 , Absolute MSE:6707208.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [48/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Training Loss: 71961.58082086267,  Validation Loss:67042.861328125 , Absolute MSE:6704286.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [49/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Training Loss: 72346.5887433979,  Validation Loss:67078.8095703125 , Absolute MSE:6707880.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [50/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Training Loss: 72025.62246919014,  Validation Loss:67069.51953125 , Absolute MSE:6706952.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [51/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Training Loss: 72134.56024427817,  Validation Loss:67061.076171875 , Absolute MSE:6706107.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [52/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Training Loss: 71993.43370378521,  Validation Loss:67059.5537109375 , Absolute MSE:6705955.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [53/1000]: 100%|██████████| 71/71 [00:16<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Training Loss: 72239.13847931338,  Validation Loss:67056.2919921875 , Absolute MSE:6705629.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [54/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Training Loss: 72613.8817671655,  Validation Loss:67057.716796875 , Absolute MSE:6705771.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [55/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Training Loss: 71954.55100132042,  Validation Loss:67054.29833984375 , Absolute MSE:6705430.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [56/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Training Loss: 72284.08676276408,  Validation Loss:67051.541015625 , Absolute MSE:6705154.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [57/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Training Loss: 71892.57994058098,  Validation Loss:67054.08740234375 , Absolute MSE:6705408.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [58/1000]: 100%|██████████| 71/71 [00:16<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Training Loss: 72217.3604753521,  Validation Loss:67051.87841796875 , Absolute MSE:6705187.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [59/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Training Loss: 72395.8164612676,  Validation Loss:67050.66845703125 , Absolute MSE:6705066.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [60/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Training Loss: 72082.37747579225,  Validation Loss:67051.048828125 , Absolute MSE:6705104.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [61/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61, Training Loss: 72299.26501980633,  Validation Loss:67052.52978515625 , Absolute MSE:6705252.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [62/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, Training Loss: 72179.47089568662,  Validation Loss:67051.51611328125 , Absolute MSE:6705151.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [63/1000]: 100%|██████████| 71/71 [00:20<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, Training Loss: 72359.20626100352,  Validation Loss:67053.2431640625 , Absolute MSE:6705323.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [64/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64, Training Loss: 72325.26749559859,  Validation Loss:67047.60205078125 , Absolute MSE:6704760.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [65/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, Training Loss: 72234.47810299296,  Validation Loss:67048.71484375 , Absolute MSE:6704871.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [66/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, Training Loss: 71999.17352552817,  Validation Loss:67050.52978515625 , Absolute MSE:6705052.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [67/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, Training Loss: 72051.40069322183,  Validation Loss:67046.3994140625 , Absolute MSE:6704639.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [68/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, Training Loss: 72421.54049295775,  Validation Loss:67050.35888671875 , Absolute MSE:6705036.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [69/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69, Training Loss: 72175.27299735915,  Validation Loss:67049.89697265625 , Absolute MSE:6704989.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [70/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Training Loss: 72132.16164172535,  Validation Loss:67052.79296875 , Absolute MSE:6705279.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [71/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71, Training Loss: 72031.14524647887,  Validation Loss:67052.5087890625 , Absolute MSE:6705250.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [72/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72, Training Loss: 72356.21027728873,  Validation Loss:67052.66455078125 , Absolute MSE:6705266.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [73/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73, Training Loss: 72117.6689040493,  Validation Loss:67050.43310546875 , Absolute MSE:6705043.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [74/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74, Training Loss: 72288.86020026408,  Validation Loss:67049.87158203125 , Absolute MSE:6704987.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [75/1000]: 100%|██████████| 71/71 [00:17<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, Training Loss: 72050.5889084507,  Validation Loss:67048.3720703125 , Absolute MSE:6704837.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [76/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76, Training Loss: 72363.19503741198,  Validation Loss:67048.94873046875 , Absolute MSE:6704895.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [77/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77, Training Loss: 72013.66549295775,  Validation Loss:67049.48974609375 , Absolute MSE:6704948.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [78/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78, Training Loss: 72269.12863116198,  Validation Loss:67052.02197265625 , Absolute MSE:6705202.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [79/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79, Training Loss: 72508.2881272007,  Validation Loss:67049.4462890625 , Absolute MSE:6704944.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [80/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Training Loss: 72139.74378301056,  Validation Loss:67054.93896484375 , Absolute MSE:6705494.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [81/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81, Training Loss: 71973.74818441902,  Validation Loss:67052.9619140625 , Absolute MSE:6705296.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [82/1000]: 100%|██████████| 71/71 [00:16<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82, Training Loss: 72435.99152728873,  Validation Loss:67051.49951171875 , Absolute MSE:6705150.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [83/1000]: 100%|██████████| 71/71 [00:17<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83, Training Loss: 72422.84000880281,  Validation Loss:67051.548828125 , Absolute MSE:6705155.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [84/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84, Training Loss: 72106.28515625,  Validation Loss:67052.15234375 , Absolute MSE:6705215.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [85/1000]: 100%|██████████| 71/71 [00:18<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85, Training Loss: 72466.14106514085,  Validation Loss:67049.5849609375 , Absolute MSE:6704958.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [86/1000]: 100%|██████████| 71/71 [00:16<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86, Training Loss: 72095.05633802817,  Validation Loss:67050.1083984375 , Absolute MSE:6705010.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [87/1000]: 100%|██████████| 71/71 [00:17<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, Training Loss: 72024.59848151408,  Validation Loss:67051.96044921875 , Absolute MSE:6705196.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [88/1000]:  21%|██        | 15/71 [00:04<00:16,  3.45it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     29\u001b[39m loss = lossFn(output, batchY)\n\u001b[32m     30\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m optimizer.step()\n\u001b[32m     33\u001b[39m runningLoss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.cuda.empty_cache()\n",
    "# print(device)\n",
    "# model.load_state_dict(torch.load(\"./models/modelF/medium_model_0.0062230645.pth\"))  \n",
    "\n",
    "trainDataLoader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "testDataLoader = DataLoader(validation_dataset, batch_size=128)\n",
    "model.to(device)\n",
    "# Training setup\n",
    "epochs = 1000\n",
    "lossFn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "tLoss = 10000\n",
    "vLoss = 10000\n",
    "# Iused 0.0008, 0.0001\n",
    "\n",
    "for each_epoch in range(epochs):\n",
    "    model.train()\n",
    "    runningLoss = 0.0\n",
    "    loop = tqdm(trainDataLoader, desc=f\"Epoch [{each_epoch+1}/{epochs}]\")\n",
    "    totalSamples = 0\n",
    "    for batchX, batchY, _ in loop:\n",
    "        batchX, batchY = batchX.to(device, non_blocking=True), batchY.to(device, non_blocking=True)\n",
    "        output = model(batchX)\n",
    "        # print(\"Pred Training Shape: \", output.shape,\"True Value\", batchY.shape)\n",
    "        # break\n",
    "        loss = lossFn(output, batchY)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.item()\n",
    "        totalSamples += batchX.size(0)\n",
    "\n",
    "    avgLoss = runningLoss/len(trainDataLoader)\n",
    "    # print(avgLoss)#, runningLoss, len(trainDataLoader.dataset))    \n",
    "    # break\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        testloss = 0.0\n",
    "        unnorm_loss = 0.0\n",
    "        for testX, testY, origin in testDataLoader:\n",
    "            testX, testY, origin = testX.to(device), testY.to(device), origin.to(device)\n",
    "    \n",
    "            pred = model(testX)\n",
    "            # print(pred.shape, testY.shape, origin.shape)\n",
    "            origin = origin.unsqueeze(1).expand(-1, 60, -1)\n",
    "            # print(pred+origin)\n",
    "            # break\n",
    "            loss = lossFn(pred, testY)\n",
    "            pred_absolute = (pred * 10) + origin \n",
    "            true_unnorm = (testY * 10) + origin\n",
    "    \n",
    "            testloss += loss.item()\n",
    "\n",
    "            unnorm_loss += nn.MSELoss()(pred_absolute, true_unnorm).item()\n",
    "        \n",
    "        avgtestloss = testloss / len(testDataLoader)\n",
    "        avgUnnormLoss = unnorm_loss /len(testDataLoader)\n",
    "\n",
    "    # break\n",
    "    print(f\"Epoch {each_epoch + 1}, Training Loss: {avgLoss:},  Validation Loss:{avgtestloss:} , Absolute MSE:{avgUnnormLoss}\")\n",
    "    # break\n",
    "    if(avgLoss < tLoss and avgtestloss < vLoss):\n",
    "        tLoss = avgLoss\n",
    "        vLoss = avgtestloss\n",
    "        torch.save(model.state_dict(), f'./models/modelL/medium_model_{avgLoss:.10f}.pth')\n",
    "\n",
    "    with open(\"./models/modelL/log_loss.txt\", 'a') as f:\n",
    "        f.write(f\"{each_epoch + 1},{avgLoss:.10f},{avgtestloss:.10f},\\n\")\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ddc8930a-a6a3-4b62-b583-bd299f41bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = torch.randn(32, 60, 2)  \n",
    "# B = torch.randn(32, 2)      \n",
    "# print(B)\n",
    "# # Expand B to shape (32, 60, 2)\n",
    "# B_expanded = B.unsqueeze(1).expand(-1, 10, -1)\n",
    "# B_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c578d1-034e-4206-8569-7f3a39a35817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee90a0a-b951-46c7-a072-7452e1b367ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872d55a8-5a22-42c0-9011-2e4d542eacf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c51ed3-cc10-4195-82b3-0026c3557f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
