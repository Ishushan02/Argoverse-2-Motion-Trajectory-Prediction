{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c35b93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_data import getData\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from read_data import LargeDataset\n",
    "import gc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "651b9bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data's shape is (10000, 50, 110, 6) and Test Data's is (10000, 50, 110, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10000, 50, 110, 6), (2100, 50, 50, 6))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata, testData = getData(\"data\")\n",
    "traindata.shape, testData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "536134a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(traindata, axis=(0, 1, 2))\n",
    "train_std = np.std(traindata, axis=(0, 1, 2))\n",
    "train_std = np.where(train_std == 0, 1.0, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f52d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowedNormalizedDataset(Dataset):\n",
    "    def __init__(self, data, window_size=40, forecast_horizon=10, mean=None, std=None):\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "        # Precompute indices of valid (sample, t) combinations\n",
    "        self.indices = []\n",
    "        for sample in range(data.shape[0]):\n",
    "            for t in range(data.shape[2] - window_size - forecast_horizon + 1):\n",
    "                self.indices.append((sample, t))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_idx, t = self.indices[idx]\n",
    "        \n",
    "        x = self.data[sample_idx, :, t:t+self.window_size, :]  # shape: (50, 40, 6)\n",
    "        y = self.data[sample_idx, 0, t+self.window_size:t+self.window_size+self.forecast_horizon, :2]  # shape: (10, 2)\n",
    "\n",
    "        if self.mean is not None and self.std is not None:\n",
    "            x = (x - self.mean) / self.std\n",
    "        \n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "\n",
    "dataset = WindowedNormalizedDataset(traindata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00f1212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createDataset(data, window_size = 40, forecast_horizon = 10):\n",
    "#     X = []\n",
    "#     y = []\n",
    "\n",
    "#     for sample in range(data.shape[0]):\n",
    "#         for t in range(data.shape[2] - window_size - forecast_horizon + 1):\n",
    "#             x_window = data[sample, :, t:t+window_size, :]\n",
    "#             y_window = data[sample, 0, t+window_size:t+window_size+forecast_horizon, :2]\n",
    "            \n",
    "#             X.append(x_window)\n",
    "#             y.append(y_window)\n",
    "    \n",
    "#     return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# X, Y = createDataset(traindata)\n",
    "# X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6696bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b = X[:10000], Y[:10000]\n",
    "# a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee31b86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 6])\n",
      "torch.Size([1, 10, 2])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\")\n",
    "\n",
    "class SmallNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size = 6, hidden_size = 64, num_layers = 5, batch_first = True)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(64)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(10)\n",
    "        self.linear1 = nn.Linear(64, 32)\n",
    "        self.linear2 = nn.Linear(32, 16)\n",
    "        self.linear3 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1, x.size(-1))\n",
    "        print(x.size())\n",
    "\n",
    "        x, temp = self.lstm(x) # Output shape [batch, seq_len, 64]\n",
    "        x = x.permute(0, 2, 1)  # [batch, 64, seq_len]\n",
    "       \n",
    "\n",
    "        x = self.pool(x)  # Forces output to [batch, 64, 10]\n",
    "        x = self.batch_norm1(x)\n",
    "        x = x.permute(0, 2, 1)  # [batch, 10, 64]\n",
    "        x = self.linear1(x)\n",
    "        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "model = SmallNetwork()\n",
    "# model.to(device)\n",
    "\n",
    "test = torch.randn(1, 2, 2, 6)\n",
    "out = model(test)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b503d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]:  12%|█▏        | 1170/9532 [06:27<46:10,  3.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m     loss.backward()\n\u001b[32m     22\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     runningLoss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m avgLoss = runningLoss / \u001b[38;5;28mlen\u001b[39m(trainDataLoader)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m each_epoch % \u001b[32m5\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# trainDataset = LargeDataset(a, b, train_mean, train_std) # testing for small dataset a, b\n",
    "trainDataLoader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Training setup\n",
    "epochs = 100\n",
    "lossFn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for each_epoch in range(epochs):\n",
    "    model.train()\n",
    "    runningLoss = 0.0\n",
    "    loop = tqdm(trainDataLoader, desc=f\"Epoch [{each_epoch+1}/{epochs}]\")\n",
    "\n",
    "    for batchX, batchY in loop:\n",
    "        batchX, batchY = batchX.to(device, non_blocking=True), batchY.to(device, non_blocking=True)\n",
    "        output = model(batchX)\n",
    "        loss = lossFn(output, batchY)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.item()\n",
    "\n",
    "    avgLoss = runningLoss / len(trainDataLoader)\n",
    "\n",
    "    if each_epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), f'./models/small_model_{each_epoch}.pth')\n",
    "        print(f\"Epoch {each_epoch + 1}, Training Loss: {avgLoss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc6704b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
