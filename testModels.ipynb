{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76b554cc-2500-48ac-98af-73f959d09a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b328dfab-1847-4f3f-bda2-4c917232d056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Apple GPU\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf78a07-ee75-414a-a2df-a3cf74e5c800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data's shape is (10000, 50, 110, 6) and Test Data's is (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "def getData(path):\n",
    "    train_file = np.load(path+\"/train.npz\")\n",
    "    train_data = train_file['data']\n",
    "    test_file = np.load(path+\"/test_input.npz\")\n",
    "    test_data = test_file['data']\n",
    "    print(f\"Training Data's shape is {train_data.shape} and Test Data's is {test_data.shape}\")\n",
    "    return train_data, test_data\n",
    "trainData, testData = getData(\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f72e2f9-f680-48ab-9a24-a83571e63358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowedNormalizedDataset(Dataset):\n",
    "    def __init__(self, data, scale=10.0):\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "        self.dt = 0.1  # Assuming fixed time step of 0.1 seconds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scene = self.data[idx].copy()\n",
    "        presence = (scene[..., 0] != 0) | (scene[..., 1] != 0)\n",
    "\n",
    "        origin = scene[0, 49].copy()\n",
    "        tx, ty, _, _, theta, _ = origin\n",
    "\n",
    "        cos_theta = np.cos(-theta)\n",
    "        sin_theta = np.sin(-theta)\n",
    "\n",
    "        # Increase feature dimension to 14 for new features\n",
    "\n",
    "        # --- Existing features (0-8) ---\n",
    "        # ... [Keep existing normalization code for positions, velocities, heading, etc.] ...\n",
    "        # normalized_scene[..., 0] to [..., 8] as original\n",
    "        normalized_scene = np.zeros((50, 110, 11), dtype=np.float32)\n",
    "\n",
    "        # --- Normalize positions ---\n",
    "        x = scene[..., 0] - tx\n",
    "        y = scene[..., 1] - ty\n",
    "        x_n = x * cos_theta - y * sin_theta\n",
    "        y_n = x * sin_theta + y * cos_theta\n",
    "        normalized_scene[..., 0] = x_n / self.scale\n",
    "        normalized_scene[..., 1] = y_n / self.scale\n",
    "\n",
    "        # --- Normalize velocities ---\n",
    "        vx = scene[..., 2]\n",
    "        vy = scene[..., 3]\n",
    "        vx_n = vx * cos_theta - vy * sin_theta\n",
    "        vy_n = vx * sin_theta + vy * cos_theta\n",
    "        normalized_scene[..., 2] = vx_n / self.scale\n",
    "        normalized_scene[..., 3] = vy_n / self.scale\n",
    "\n",
    "        # --- Heading normalization ---\n",
    "        heading = scene[..., 4]\n",
    "        normalized_heading = heading - theta\n",
    "        normalized_heading = (normalized_heading + np.pi) % (2 * np.pi) - np.pi\n",
    "        normalized_scene[..., 4] = normalized_heading\n",
    "\n",
    "        # --- agent_type (already encoded) ---\n",
    "        normalized_scene[..., 5] = scene[..., 5]  # agent_type\n",
    "\n",
    "        # --- Presence ---\n",
    "        normalized_scene[..., 6] = presence.astype(np.float32)\n",
    "\n",
    "   \n",
    "\n",
    "        # === New Feature 2: Speed ===\n",
    "        speed = np.sqrt(vx ** 2 + vy ** 2)\n",
    "        normalized_scene[..., 7] = speed / self.scale  # scale to keep consistent magnitude\n",
    "\n",
    "        # === New Feature 3: Distance to ego ===\n",
    "        ego_pos = scene[0, :, :2]  # (110, 2)\n",
    "        dist_to_ego = np.linalg.norm(scene[..., :2] - ego_pos[None, :, :], axis=-1)\n",
    "        normalized_scene[..., 8] = dist_to_ego / self.scale\n",
    "\n",
    "        # === New Feature 1: Minimum Distance to Any Agent (Dynamic Interaction) ===\n",
    "        positions = scene[..., :2]  # Original positions (50, 110, 2)\n",
    "        # dist_matrix = np.linalg.norm(\n",
    "        #     positions[:, :, None, :] - positions[:, None, :, :], \n",
    "        #     axis=-1\n",
    "        # )\n",
    "        # np.fill_diagonal(dist_matrix, np.inf)  # Ignore self-distance\n",
    "        # min_dists = np.min(dist_matrix, axis=2)  # (50, 110)\n",
    "        # normalized_scene[..., 9] = min_dists / self.scale  # Feature index 9\n",
    "\n",
    "        # === New Feature 2: Acceleration Magnitude (Motion Dynamics) ===\n",
    "        vx = scene[..., 2]\n",
    "        vy = scene[..., 3]\n",
    "        speed = np.sqrt(vx**2 + vy**2)\n",
    "        \n",
    "        # Compute acceleration (delta-v / delta-t)\n",
    "        accel = np.zeros_like(speed)\n",
    "        accel[:, 1:] = (speed[:, 1:] - speed[:, :-1]) / self.dt\n",
    "        accel[:, 0] = accel[:, 1]  # Handle first timestep\n",
    "        \n",
    "        normalized_scene[..., 9] = accel / (self.scale / self.dt)  # Feature index 10\n",
    "\n",
    "        # === New Feature 3: Time-to-Collision (TTC) with Ego (Critical Event Metric) ===\n",
    "        rel_speed = np.sqrt(\n",
    "            (vx - vx[0:1])**2 + \n",
    "            (vy - vy[0:1])**2\n",
    "        )\n",
    "        dist_to_ego = np.linalg.norm(\n",
    "            positions - positions[0:1], \n",
    "            axis=-1\n",
    "        )\n",
    "        \n",
    "        ttc = dist_to_ego / (rel_speed + 1e-5)  # Avoid division by zero\n",
    "        ttc = np.clip(ttc, 0, 10)  # Clip to meaningful range (0-10s)\n",
    "        normalized_scene[..., 10] = ttc / 10.0  # Feature index 11 (scaled 0-1)\n",
    "\n",
    "        # --- Masking ---\n",
    "        missing_mask = np.expand_dims(~presence, -1)\n",
    "        normalized_scene[..., :11] = np.where(missing_mask, 0, normalized_scene[..., :11])\n",
    "\n",
    "        # Inputs: first 50 timesteps\n",
    "        X = normalized_scene[:, :50, :]  # Now (50, 50, 14 features)\n",
    "\n",
    "        # Target: ego future positions and presence\n",
    "        ego_future = normalized_scene[0, 50:]\n",
    "        Y = np.zeros((60, 3), dtype=np.float32)\n",
    "        Y[:, :2] = ego_future[:, :2]\n",
    "        Y[:, 2] = ego_future[:, 6]  # presence\n",
    "\n",
    "        return (\n",
    "            torch.tensor(X, dtype=torch.float32),\n",
    "            torch.tensor(Y, dtype=torch.float32),\n",
    "            torch.tensor(origin, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eadf117-228c-4f2e-a595-0dbff4a096f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowedNormalizedTestDataset(Dataset):\n",
    "    def __init__(self, data, scale=10.0):\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "        self.dt = 0.1  # Assuming fixed time step of 0.1 seconds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scene = self.data[idx].copy()\n",
    "        presence = (scene[..., 0] != 0) | (scene[..., 1] != 0)\n",
    "\n",
    "        origin = scene[0, 49].copy()\n",
    "        tx, ty, _, _, theta, _ = origin\n",
    "\n",
    "        cos_theta = np.cos(-theta)\n",
    "        sin_theta = np.sin(-theta)\n",
    "\n",
    "        # Increase feature dimension to 14 for new features\n",
    "\n",
    "        # --- Existing features (0-8) ---\n",
    "        # ... [Keep existing normalization code for positions, velocities, heading, etc.] ...\n",
    "        # normalized_scene[..., 0] to [..., 8] as original\n",
    "        normalized_scene = np.zeros((50, 50, 11), dtype=np.float32)\n",
    "\n",
    "        # --- Normalize positions ---\n",
    "        x = scene[..., 0] - tx\n",
    "        y = scene[..., 1] - ty\n",
    "        x_n = x * cos_theta - y * sin_theta\n",
    "        y_n = x * sin_theta + y * cos_theta\n",
    "        normalized_scene[..., 0] = x_n / self.scale\n",
    "        normalized_scene[..., 1] = y_n / self.scale\n",
    "\n",
    "        # --- Normalize velocities ---\n",
    "        vx = scene[..., 2]\n",
    "        vy = scene[..., 3]\n",
    "        vx_n = vx * cos_theta - vy * sin_theta\n",
    "        vy_n = vx * sin_theta + vy * cos_theta\n",
    "        normalized_scene[..., 2] = vx_n / self.scale\n",
    "        normalized_scene[..., 3] = vy_n / self.scale\n",
    "\n",
    "        # --- Heading normalization ---\n",
    "        heading = scene[..., 4]\n",
    "        normalized_heading = heading - theta\n",
    "        normalized_heading = (normalized_heading + np.pi) % (2 * np.pi) - np.pi\n",
    "        normalized_scene[..., 4] = normalized_heading\n",
    "\n",
    "        # --- agent_type (already encoded) ---\n",
    "        normalized_scene[..., 5] = scene[..., 5]  # agent_type\n",
    "\n",
    "        # --- Presence ---\n",
    "        normalized_scene[..., 6] = presence.astype(np.float32)\n",
    "\n",
    "   \n",
    "\n",
    "        # === New Feature 2: Speed ===\n",
    "        speed = np.sqrt(vx ** 2 + vy ** 2)\n",
    "        normalized_scene[..., 7] = speed / self.scale  # scale to keep consistent magnitude\n",
    "\n",
    "        # === New Feature 3: Distance to ego ===\n",
    "        ego_pos = scene[0, :, :2]  # (110, 2)\n",
    "        dist_to_ego = np.linalg.norm(scene[..., :2] - ego_pos[None, :, :], axis=-1)\n",
    "        normalized_scene[..., 8] = dist_to_ego / self.scale\n",
    "\n",
    "        # === New Feature 1: Minimum Distance to Any Agent (Dynamic Interaction) ===\n",
    "        positions = scene[..., :2]  # Original positions (50, 110, 2)\n",
    "        # dist_matrix = np.linalg.norm(\n",
    "        #     positions[:, :, None, :] - positions[:, None, :, :], \n",
    "        #     axis=-1\n",
    "        # )\n",
    "        # np.fill_diagonal(dist_matrix, np.inf)  # Ignore self-distance\n",
    "        # min_dists = np.min(dist_matrix, axis=2)  # (50, 110)\n",
    "        # normalized_scene[..., 9] = min_dists / self.scale  # Feature index 9\n",
    "\n",
    "        # === New Feature 2: Acceleration Magnitude (Motion Dynamics) ===\n",
    "        vx = scene[..., 2]\n",
    "        vy = scene[..., 3]\n",
    "        speed = np.sqrt(vx**2 + vy**2)\n",
    "        \n",
    "        # Compute acceleration (delta-v / delta-t)\n",
    "        accel = np.zeros_like(speed)\n",
    "        accel[:, 1:] = (speed[:, 1:] - speed[:, :-1]) / self.dt\n",
    "        accel[:, 0] = accel[:, 1]  # Handle first timestep\n",
    "        \n",
    "        normalized_scene[..., 9] = accel / (self.scale / self.dt)  # Feature index 10\n",
    "\n",
    "        # === New Feature 3: Time-to-Collision (TTC) with Ego (Critical Event Metric) ===\n",
    "        rel_speed = np.sqrt(\n",
    "            (vx - vx[0:1])**2 + \n",
    "            (vy - vy[0:1])**2\n",
    "        )\n",
    "        dist_to_ego = np.linalg.norm(\n",
    "            positions - positions[0:1], \n",
    "            axis=-1\n",
    "        )\n",
    "        \n",
    "        ttc = dist_to_ego / (rel_speed + 1e-5)  # Avoid division by zero\n",
    "        ttc = np.clip(ttc, 0, 10)  # Clip to meaningful range (0-10s)\n",
    "        normalized_scene[..., 10] = ttc / 10.0  # Feature index 11 (scaled 0-1)\n",
    "\n",
    "        # --- Masking ---\n",
    "        missing_mask = np.expand_dims(~presence, -1)\n",
    "        normalized_scene[..., :11] = np.where(missing_mask, 0, normalized_scene[..., :11])\n",
    "\n",
    "        # Inputs: first 50 timesteps\n",
    "        X = normalized_scene[:, :50, :]  # Now (50, 50, 14 features)\n",
    "\n",
    "        # Target: ego future positions and presence\n",
    "        # ego_future = normalized_scene[0, 50:]\n",
    "        # Y = np.zeros((60, 3), dtype=np.float32)\n",
    "        # Y[:, :2] = ego_future[:, :2]\n",
    "        # Y[:, 2] = ego_future[:, 6]  # presence\n",
    "\n",
    "        return (\n",
    "            torch.tensor(X, dtype=torch.float32),\n",
    "            # torch.tensor(Y, dtype=torch.float32),\n",
    "            torch.tensor(origin, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c26c470e-3645-4bcc-8c35-09774c8c8fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_ego_batch(predicted, origin, scale=10.0):\n",
    "    \"\"\"\n",
    "    Convert batch of normalized (and scaled) ego predictions back to global coordinates.\n",
    "\n",
    "    predicted: (B, ..., 2) tensor of normalized [x, y] positions\n",
    "    origin: (B, 6) tensor of ego's reference state at t=49\n",
    "    Returns:\n",
    "        (B, ..., 2) tensor of global [x, y] positions\n",
    "    \"\"\"\n",
    "    tx = origin[:, 0]  # (B,)\n",
    "    ty = origin[:, 1]  # (B,)\n",
    "    theta = origin[:, 4]  # (B,)\n",
    "\n",
    "    cos_theta = torch.cos(theta)\n",
    "    sin_theta = torch.sin(theta)\n",
    "\n",
    "    # Expand for broadcasting\n",
    "    while len(cos_theta.shape) < len(predicted.shape) - 1:\n",
    "        cos_theta = cos_theta.unsqueeze(1)\n",
    "        sin_theta = sin_theta.unsqueeze(1)\n",
    "        tx = tx.unsqueeze(1)\n",
    "        ty = ty.unsqueeze(1)\n",
    "\n",
    "    # Unscale before denormalizing\n",
    "    x = predicted[..., 0] * scale\n",
    "    y = predicted[..., 1] * scale\n",
    "\n",
    "    # Rotate\n",
    "    x_rot = x * cos_theta - y * sin_theta\n",
    "    y_rot = x * sin_theta + y * cos_theta\n",
    "\n",
    "    # Translate\n",
    "    x_global = x_rot + tx\n",
    "    y_global = y_rot + ty\n",
    "\n",
    "    return torch.stack([x_global, y_global], dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b698a36-6836-4114-a4ac-745265b21283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0000,  0.0000,  0.8006,  0.0019,  0.0000,  0.0000,  1.0000,  0.8006,\n",
       "          0.0000, -0.0057,  0.0000]),\n",
       " tensor([7.8468e-02, 9.1270e-05, 1.0000e+00]),\n",
       " torch.Size([6]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = WindowedNormalizedDataset(trainData)\n",
    "X, Y, origin = data.__getitem__(1)\n",
    "X[0, 49, :], Y[0, :], origin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "054067a5-39a6-4d7b-a72c-733c8b27bd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 50, 50, 11])\n",
      "Output shape: torch.Size([1, 60, 2])\n",
      "\n",
      "Model parameters: 8,261,240\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TrajectoryTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=550, model_dim=256, num_heads=8, num_layers=6, dropout=0.1, pred_len=60, num_agents=50):\n",
    "        super().__init__()\n",
    "        self.model_dim = model_dim\n",
    "        self.pred_len = pred_len\n",
    "        self.num_agents = num_agents\n",
    "        \n",
    "        # Process each agent's full trajectory (50*7 = 350) into a single token\n",
    "        self.trajectory_encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, model_dim),\n",
    "            nn.LayerNorm(model_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(model_dim, model_dim),\n",
    "            nn.LayerNorm(model_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(model_dim, model_dim),\n",
    "            nn.LayerNorm(model_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 2-layer transformer encoder to process agent tokens\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=model_dim, \n",
    "                nhead=num_heads, \n",
    "                dropout=dropout, \n",
    "                batch_first=True\n",
    "            ),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        # Final linear layer to predict ego vehicle trajectory\n",
    "        self.output_fcpre = nn.Linear(model_dim, model_dim)  # 60*2 = 120\n",
    "        self.output_fc = nn.Linear(model_dim, pred_len * 2)  # 60*2 = 120\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, N, T, Ft = x.shape\n",
    "        \n",
    "        x = x.view(B, N, T * Ft)  # (B, 50, 350)\n",
    "        \n",
    "        # Encode each agent's trajectory into a token\n",
    "        agent_tokens = self.trajectory_encoder(x)  # (B, 50, model_dim)\n",
    "        \n",
    "        # Process all agent tokens through transformer\n",
    "        encoded_tokens = self.transformer_encoder(agent_tokens)  # (B, 50, model_dim)\n",
    "        \n",
    "        # Extract ego vehicle token (assuming agent 0 is ego)\n",
    "        ego_token = encoded_tokens[:, 0, :]  # (B, model_dim)\n",
    "        \n",
    "        # Predict ego trajectory\n",
    "        output = F.relu(self.output_fcpre(ego_token))  # (B, pred_len*2)\n",
    "\n",
    "        output = self.output_fc(output)  # (B, pred_len*2)\n",
    "        \n",
    "        # Reshape to (B, pred_len, 2)\n",
    "        output = output.view(B, self.pred_len, 2)  # (B, 60, 2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Test run\n",
    "model = TrajectoryTransformer()\n",
    "x = torch.randn(1, 50, 50, 11)  \n",
    "out = model(x)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {out.shape}\")  # Expected: (1, 60, 2)\n",
    "\n",
    "# Print model summary\n",
    "print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daeacf4c-5c20-4d07-bec7-59b3882a3c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 8261240\n"
     ]
    }
   ],
   "source": [
    "model = TrajectoryTransformer().to(device=device)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97d72603-95a3-4c9e-a684-1710481b50ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (9000, 50, 110, 6)\n",
      "Validation shape: (1000, 50, 110, 6)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "num_samples = trainData.shape[0]\n",
    "indices = np.random.permutation(num_samples)\n",
    "split_index = int(0.9 * num_samples)\n",
    "train_idx, val_idx = indices[:split_index], indices[split_index:]\n",
    "\n",
    "# Split the data\n",
    "train_data = trainData[train_idx]\n",
    "val_data = trainData[val_idx]\n",
    "\n",
    "print(\"Train shape:\", train_data.shape)\n",
    "print(\"Validation shape:\", val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4da16df3-a288-4ccd-942f-ebe299a4f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTensor = WindowedNormalizedDataset(train_data)\n",
    "testTensor = WindowedNormalizedDataset(val_data)\n",
    "train_dataloader = DataLoader(trainTensor, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(testTensor, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceaaea0-c7d7-498a-84fd-f3f58e99bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = WindowedNormalizedTestDataset(testData)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "\n",
    "best_model = torch.load(\"./models/modelI/best_model_.pt\")\n",
    "model = model = TrajectoryTransformer().to(device=device)\n",
    "# model = model = TrajectoryTransformerPlus().to(device=device)\n",
    "\n",
    "\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "pred_list = []\n",
    "with torch.no_grad():\n",
    "    for batchX, origin in test_loader:\n",
    "        batchX = batchX.to(device)\n",
    "        # batchY = batchY.to(device)\n",
    "        origin = origin.to(device)\n",
    "\n",
    "        \n",
    "        pred = model(batchX)  # pred shape: (B, 60, 2)\n",
    "        \n",
    "        unnorm_pred = denormalize_ego_batch(pred[..., :2], origin)\n",
    "        # print(unnorm_pred.shape)\n",
    "        pred_list.append(unnorm_pred.cpu().numpy())\n",
    "        # print(len(pred))\n",
    "        \n",
    "\n",
    "pred_list = np.concatenate(pred_list, axis=0)  \n",
    "pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n",
    "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
    "output_df.index.name = 'index'\n",
    "output_df.to_csv('./models/modelI/testTransFormer.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817b43e-4deb-4182-b52b-7471af4b28a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
