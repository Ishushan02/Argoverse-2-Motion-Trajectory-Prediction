{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c35b93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_data import getData\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from read_data import LargeDataset\n",
    "import gc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "651b9bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data's shape is (10000, 50, 110, 6) and Test Data's is (10000, 50, 110, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10000, 50, 110, 6), (2100, 50, 50, 6))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata, testData = getData(\"data\")\n",
    "traindata.shape, testData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "536134a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(traindata, axis=(0, 1, 2))\n",
    "train_std = np.std(traindata, axis=(0, 1, 2))\n",
    "train_std = np.where(train_std == 0, 1.0, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f52d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowedNormalizedDataset(Dataset):\n",
    "    def __init__(self, data, window_size=40, forecast_horizon=10, mean=None, std=None):\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "        # Precompute indices of valid (sample, t) combinations\n",
    "        self.indices = []\n",
    "        for sample in range(data.shape[0]):\n",
    "            for t in range(data.shape[2] - window_size - forecast_horizon + 1):\n",
    "                self.indices.append((sample, t))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_idx, t = self.indices[idx]\n",
    "        \n",
    "        x = self.data[sample_idx, :, t:t+self.window_size, :]  # shape: (50, 40, 6)\n",
    "        y = self.data[sample_idx, 0, t+self.window_size:t+self.window_size+self.forecast_horizon, :2]  # shape: (10, 2)\n",
    "\n",
    "        if self.mean is not None and self.std is not None:\n",
    "            x = (x - self.mean) / self.std\n",
    "        \n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "\n",
    "dataset = WindowedNormalizedDataset(traindata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00f1212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createDataset(data, window_size = 40, forecast_horizon = 10):\n",
    "#     X = []\n",
    "#     y = []\n",
    "\n",
    "#     for sample in range(data.shape[0]):\n",
    "#         for t in range(data.shape[2] - window_size - forecast_horizon + 1):\n",
    "#             x_window = data[sample, :, t:t+window_size, :]\n",
    "#             y_window = data[sample, 0, t+window_size:t+window_size+forecast_horizon, :2]\n",
    "            \n",
    "#             X.append(x_window)\n",
    "#             y.append(y_window)\n",
    "    \n",
    "#     return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# X, Y = createDataset(traindata)\n",
    "# X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6696bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 50, 40, 6), (10000, 10, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a, b = X[:10000], Y[:10000]\n",
    "# a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee31b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "\n",
    "class SmallNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size = 6, hidden_size = 64, num_layers = 5, batch_first = True)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(64)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(10)\n",
    "        self.linear1 = nn.Linear(64, 32)\n",
    "        self.linear2 = nn.Linear(32, 16)\n",
    "        self.linear3 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1, x.size(-1))\n",
    "\n",
    "        x, temp = self.lstm(x) # Output shape [batch, seq_len, 64]\n",
    "        x = x.permute(0, 2, 1)  # [batch, 64, seq_len]\n",
    "       \n",
    "\n",
    "        x = self.pool(x)  # Forces output to [batch, 64, 10]\n",
    "        x = self.batch_norm1(x)\n",
    "        x = x.permute(0, 2, 1)  # [batch, 10, 64]\n",
    "        x = self.linear1(x)\n",
    "        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.nn.functional.leaky_relu(x, negative_slope=0.01)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "model = SmallNetwork()\n",
    "# model.to(device)\n",
    "\n",
    "# test = torch.randn(2, 2, 2, 6)\n",
    "# out = model(test)\n",
    "# print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b503d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]: 100%|██████████| 9532/9532 [53:54<00:00,  2.95it/s]  \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ./models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m avgLoss = runningLoss / \u001b[38;5;28mlen\u001b[39m(trainDataLoader)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m each_epoch % \u001b[32m5\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./models/small_model_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43meach_epoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.pth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meach_epoch\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Training Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavgLoss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/serialization.py:943\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    940\u001b[39m _check_save_filelike(f)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m    944\u001b[39m         _save(\n\u001b[32m    945\u001b[39m             obj,\n\u001b[32m    946\u001b[39m             opened_zipfile,\n\u001b[32m   (...)\u001b[39m\u001b[32m    949\u001b[39m             _disable_byteorder_record,\n\u001b[32m    950\u001b[39m         )\n\u001b[32m    951\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/serialization.py:810\u001b[39m, in \u001b[36m_open_zipfile_writer\u001b[39m\u001b[34m(name_or_buffer)\u001b[39m\n\u001b[32m    808\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    809\u001b[39m     container = _open_zipfile_writer_buffer\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/serialization.py:781\u001b[39m, in \u001b[36m_open_zipfile_writer_file.__init__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    777\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    778\u001b[39m         torch._C.PyTorchFileWriter(\u001b[38;5;28mself\u001b[39m.file_stream, _compute_crc32)\n\u001b[32m    779\u001b[39m     )\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m781\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_compute_crc32\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Parent directory ./models does not exist."
     ]
    }
   ],
   "source": [
    "# trainDataset = LargeDataset(a, b, train_mean, train_std) # testing for small dataset a, b\n",
    "trainDataLoader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Training setup\n",
    "epochs = 100\n",
    "lossFn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for each_epoch in range(epochs):\n",
    "    model.train()\n",
    "    runningLoss = 0.0\n",
    "    loop = tqdm(trainDataLoader, desc=f\"Epoch [{each_epoch+1}/{epochs}]\")\n",
    "\n",
    "    for batchX, batchY in loop:\n",
    "        batchX, batchY = batchX.to(device, non_blocking=True), batchY.to(device, non_blocking=True)\n",
    "        output = model(batchX)\n",
    "        loss = lossFn(output, batchY)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.item()\n",
    "\n",
    "    avgLoss = runningLoss / len(trainDataLoader)\n",
    "\n",
    "    if each_epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), f'./models/small_model_{each_epoch}.pth')\n",
    "        print(f\"Epoch {each_epoch + 1}, Training Loss: {avgLoss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc6704b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
