{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f880c27-677b-46b0-9644-fc68d0f67528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "005946f0-f957-44d1-833f-6b24c9207d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Apple GPU\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac6c9d10-944c-49bb-bced-b07c99133eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data's shape is (10000, 50, 110, 6) and Test Data's is (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "def getData(path):\n",
    "    train_file = np.load(path+\"/train.npz\")\n",
    "    train_data = train_file['data']\n",
    "    test_file = np.load(path+\"/test_input.npz\")\n",
    "    test_data = test_file['data']\n",
    "    print(f\"Training Data's shape is {train_data.shape} and Test Data's is {test_data.shape}\")\n",
    "    return train_data, test_data\n",
    "trainData, testData = getData(\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5a8358d2-020a-453f-a6d0-cad96ed725c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowedNormalizedDataset(Dataset):\n",
    "    def __init__(self, data, scale=10.0):\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "        self.dt = 0.1  # Assuming 0.1s timesteps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scene = self.data[idx].copy()  # (50 agents, 110 timesteps, 6 features)\n",
    "        presence = (scene[..., 0] != 0) | (scene[..., 1] != 0)  # (50, 110)\n",
    "\n",
    "        origin = scene[0, 49].copy()\n",
    "        tx, ty, _, _, theta, _ = origin\n",
    "\n",
    "        cos_theta = np.cos(-theta)\n",
    "        sin_theta = np.sin(-theta)\n",
    "\n",
    "        # Create feature tensor with 14 features\n",
    "        normalized_scene = np.zeros((50, 110, 14), dtype=np.float32)\n",
    "\n",
    "        # --- Existing normalization (features 0-8) ---\n",
    "        # Positions\n",
    "        x = scene[..., 0] - tx\n",
    "        y = scene[..., 1] - ty\n",
    "        x_n = x * cos_theta - y * sin_theta\n",
    "        y_n = x * sin_theta + y * cos_theta\n",
    "        normalized_scene[..., 0] = x_n / self.scale\n",
    "        normalized_scene[..., 1] = y_n / self.scale\n",
    "        \n",
    "        # Velocities\n",
    "        vx = scene[..., 2]\n",
    "        vy = scene[..., 3]\n",
    "        vx_n = vx * cos_theta - vy * sin_theta\n",
    "        vy_n = vx * sin_theta + vy * cos_theta\n",
    "        normalized_scene[..., 2] = vx_n / self.scale\n",
    "        normalized_scene[..., 3] = vy_n / self.scale\n",
    "        \n",
    "        # Heading\n",
    "        heading = scene[..., 4]\n",
    "        normalized_heading = heading - theta\n",
    "        normalized_heading = (normalized_heading + np.pi) % (2 * np.pi) - np.pi\n",
    "        normalized_scene[..., 4] = normalized_heading\n",
    "        \n",
    "        # Agent type and presence\n",
    "        normalized_scene[..., 5] = scene[..., 5]  # agent_type\n",
    "        normalized_scene[..., 6] = presence.astype(np.float32)  # presence\n",
    "        \n",
    "        # Speed\n",
    "        speed = np.sqrt(vx ** 2 + vy ** 2)\n",
    "        normalized_scene[..., 7] = speed / self.scale\n",
    "        \n",
    "        # Distance to ego\n",
    "        ego_pos = scene[0, :, :2]  # (110, 2)\n",
    "        dist_to_ego = np.linalg.norm(scene[..., :2] - ego_pos[None, :, :], axis=-1)\n",
    "        normalized_scene[..., 8] = dist_to_ego / self.scale\n",
    "\n",
    "        # === New Feature 1: Minimum Distance to Any Agent ===\n",
    "        min_dists = np.full((50, 110), 1000.0)  # Initialize with large distance\n",
    "        positions = scene[..., :2]  # Original positions (50, 110, 2)\n",
    "        \n",
    "        for t in range(110):\n",
    "            # Only consider present agents\n",
    "            present_agents = np.where(presence[:, t])[0]\n",
    "            if len(present_agents) < 2:\n",
    "                continue  # Skip if less than 2 agents present\n",
    "                \n",
    "            # Get present agents' positions\n",
    "            pos_t = positions[present_agents, t, :]\n",
    "            \n",
    "            # Compute pairwise distances\n",
    "            diff = pos_t[:, None, :] - pos_t[None, :, :]\n",
    "            dist_matrix = np.linalg.norm(diff, axis=-1)\n",
    "            \n",
    "            # Ignore self-distance\n",
    "            np.fill_diagonal(dist_matrix, np.inf)\n",
    "            \n",
    "            # Find minimum distances\n",
    "            agent_min_dists = np.min(dist_matrix, axis=1)\n",
    "            \n",
    "            # Update only present agents\n",
    "            min_dists[present_agents, t] = agent_min_dists\n",
    "        \n",
    "        normalized_scene[..., 9] = min_dists / self.scale  # Feature index 9\n",
    "\n",
    "        # === New Feature 2: Acceleration Magnitude ===\n",
    "        acceleration = np.zeros_like(speed)\n",
    "        # Forward difference for acceleration\n",
    "        acceleration[:, 1:] = (speed[:, 1:] - speed[:, :-1]) / self.dt\n",
    "        # Handle first timestep\n",
    "        acceleration[:, 0] = acceleration[:, 1]  \n",
    "        normalized_scene[..., 10] = acceleration / self.scale  # Feature index 10\n",
    "\n",
    "        # === New Feature 3: Time-to-Collision (TTC) with Ego ===\n",
    "        # Relative velocity magnitude\n",
    "        rel_vel = np.sqrt((vx - vx[0])**2 + (vy - vy[0])**2)\n",
    "        # Avoid division by zero\n",
    "        ttc = np.full((50, 110), 10.0)  # Default to max TTC (10s)\n",
    "        valid_mask = (dist_to_ego > 0.1) & (rel_vel > 0.1)\n",
    "        ttc[valid_mask] = dist_to_ego[valid_mask] / rel_vel[valid_mask]\n",
    "        # Clip to meaningful range (0-10s)\n",
    "        ttc = np.clip(ttc, 0, 10)  \n",
    "        normalized_scene[..., 11] = ttc / 10.0  # Feature index 11 (scaled 0-1)\n",
    "\n",
    "        # === Optional: Ego Agent Flag ===\n",
    "        ego_mask = (np.arange(50) == 0).astype(np.float32)[:, None]\n",
    "        normalized_scene[..., 12] = ego_mask  # Feature index 12\n",
    "\n",
    "        # === Optional: Future Velocity Angle ===\n",
    "        future_vel_angle = np.zeros((50, 110))\n",
    "        future_vel_angle[:, :-1] = np.arctan2(vy_n[:, 1:], vx_n[:, 1:])\n",
    "        normalized_scene[..., 13] = future_vel_angle  # Feature index 13\n",
    "\n",
    "        # Mask out invalid timesteps\n",
    "        missing_mask = np.expand_dims(~presence, -1)\n",
    "        normalized_scene = np.where(missing_mask, 0, normalized_scene)\n",
    "\n",
    "        # Inputs: first 50 timesteps\n",
    "        X = normalized_scene[:, :50, :]  # (50 agents, 50 timesteps, 14 features)\n",
    "\n",
    "        # Target: ego agent's future positions and presence\n",
    "        ego_future = normalized_scene[0, 50:]\n",
    "        Y = np.zeros((60, 3), dtype=np.float32)\n",
    "        Y[:, :2] = ego_future[:, :2]  # Normalized positions\n",
    "        Y[:, 2] = ego_future[:, 6]    # Presence\n",
    "\n",
    "        return (\n",
    "            torch.tensor(X, dtype=torch.float32),\n",
    "            torch.tensor(Y, dtype=torch.float32),\n",
    "            torch.tensor(origin, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "81f6dee5-7d2e-471f-b58f-fd7556b08fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowedNormalizedTestDataset(Dataset):\n",
    "    def __init__(self, data, scale=10.0):\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "        self.dt = 0.1  # Assuming 0.1s timesteps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scene = self.data[idx].copy()  # (50 agents, 110 timesteps, 6 features)\n",
    "        presence = (scene[..., 0] != 0) | (scene[..., 1] != 0)  # (50, 110)\n",
    "\n",
    "        origin = scene[0, 49].copy()\n",
    "        tx, ty, _, _, theta, _ = origin\n",
    "\n",
    "        cos_theta = np.cos(-theta)\n",
    "        sin_theta = np.sin(-theta)\n",
    "\n",
    "        # Create feature tensor with 14 features\n",
    "        normalized_scene = np.zeros((50, 50, 14), dtype=np.float32)\n",
    "\n",
    "        # --- Existing normalization (features 0-8) ---\n",
    "        # Positions\n",
    "        x = scene[..., 0] - tx\n",
    "        y = scene[..., 1] - ty\n",
    "        x_n = x * cos_theta - y * sin_theta\n",
    "        y_n = x * sin_theta + y * cos_theta\n",
    "        normalized_scene[..., 0] = x_n / self.scale\n",
    "        normalized_scene[..., 1] = y_n / self.scale\n",
    "        \n",
    "        # Velocities\n",
    "        vx = scene[..., 2]\n",
    "        vy = scene[..., 3]\n",
    "        vx_n = vx * cos_theta - vy * sin_theta\n",
    "        vy_n = vx * sin_theta + vy * cos_theta\n",
    "        normalized_scene[..., 2] = vx_n / self.scale\n",
    "        normalized_scene[..., 3] = vy_n / self.scale\n",
    "        \n",
    "        # Heading\n",
    "        heading = scene[..., 4]\n",
    "        normalized_heading = heading - theta\n",
    "        normalized_heading = (normalized_heading + np.pi) % (2 * np.pi) - np.pi\n",
    "        normalized_scene[..., 4] = normalized_heading\n",
    "        \n",
    "        # Agent type and presence\n",
    "        normalized_scene[..., 5] = scene[..., 5]  # agent_type\n",
    "        normalized_scene[..., 6] = presence.astype(np.float32)  # presence\n",
    "        \n",
    "        # Speed\n",
    "        speed = np.sqrt(vx ** 2 + vy ** 2)\n",
    "        normalized_scene[..., 7] = speed / self.scale\n",
    "        \n",
    "        # Distance to ego\n",
    "        ego_pos = scene[0, :, :2]  # (110, 2)\n",
    "        dist_to_ego = np.linalg.norm(scene[..., :2] - ego_pos[None, :, :], axis=-1)\n",
    "        normalized_scene[..., 8] = dist_to_ego / self.scale\n",
    "\n",
    "        # === New Feature 1: Minimum Distance to Any Agent ===\n",
    "        min_dists = np.full((50, 50), 1000.0)  # Initialize with large distance\n",
    "        positions = scene[..., :2]  # Original positions (50, 110, 2)\n",
    "        \n",
    "        for t in range(50):\n",
    "            # Only consider present agents\n",
    "            present_agents = np.where(presence[:, t])[0]\n",
    "            if len(present_agents) < 2:\n",
    "                continue  # Skip if less than 2 agents present\n",
    "                \n",
    "            # Get present agents' positions\n",
    "            pos_t = positions[present_agents, t, :]\n",
    "            \n",
    "            # Compute pairwise distances\n",
    "            diff = pos_t[:, None, :] - pos_t[None, :, :]\n",
    "            dist_matrix = np.linalg.norm(diff, axis=-1)\n",
    "            \n",
    "            # Ignore self-distance\n",
    "            np.fill_diagonal(dist_matrix, np.inf)\n",
    "            \n",
    "            # Find minimum distances\n",
    "            agent_min_dists = np.min(dist_matrix, axis=1)\n",
    "            \n",
    "            # Update only present agents\n",
    "            min_dists[present_agents, t] = agent_min_dists\n",
    "        \n",
    "        normalized_scene[..., 9] = min_dists / self.scale  # Feature index 9\n",
    "\n",
    "        # === New Feature 2: Acceleration Magnitude ===\n",
    "        acceleration = np.zeros_like(speed)\n",
    "        # Forward difference for acceleration\n",
    "        acceleration[:, 1:] = (speed[:, 1:] - speed[:, :-1]) / self.dt\n",
    "        # Handle first timestep\n",
    "        acceleration[:, 0] = acceleration[:, 1]  \n",
    "        normalized_scene[..., 10] = acceleration / self.scale  # Feature index 10\n",
    "\n",
    "        # === New Feature 3: Time-to-Collision (TTC) with Ego ===\n",
    "        # Relative velocity magnitude\n",
    "        rel_vel = np.sqrt((vx - vx[0])**2 + (vy - vy[0])**2)\n",
    "        # Avoid division by zero\n",
    "        ttc = np.full((50, 50), 10.0)  # Default to max TTC (10s)\n",
    "        valid_mask = (dist_to_ego > 0.1) & (rel_vel > 0.1)\n",
    "        ttc[valid_mask] = dist_to_ego[valid_mask] / rel_vel[valid_mask]\n",
    "        # Clip to meaningful range (0-10s)\n",
    "        ttc = np.clip(ttc, 0, 10)  \n",
    "        normalized_scene[..., 11] = ttc / 10.0  # Feature index 11 (scaled 0-1)\n",
    "\n",
    "        # === Optional: Ego Agent Flag ===\n",
    "        ego_mask = (np.arange(50) == 0).astype(np.float32)[:, None]\n",
    "        normalized_scene[..., 12] = ego_mask  # Feature index 12\n",
    "\n",
    "        # === Optional: Future Velocity Angle ===\n",
    "        future_vel_angle = np.zeros((50, 50))\n",
    "        future_vel_angle[:, :-1] = np.arctan2(vy_n[:, 1:], vx_n[:, 1:])\n",
    "        normalized_scene[..., 13] = future_vel_angle  # Feature index 13\n",
    "\n",
    "        # Mask out invalid timesteps\n",
    "        missing_mask = np.expand_dims(~presence, -1)\n",
    "        normalized_scene = np.where(missing_mask, 0, normalized_scene)\n",
    "\n",
    "        # Inputs: first 50 timesteps\n",
    "        X = normalized_scene[:, :50, :]  # (50 agents, 50 timesteps, 14 features)\n",
    "\n",
    "        # Target: ego agent's future positions and presence\n",
    "        # ego_future = normalized_scene[0, 50:]\n",
    "        # Y = np.zeros((60, 3), dtype=np.float32)\n",
    "        # Y[:, :2] = ego_future[:, :2]  # Normalized positions\n",
    "        # Y[:, 2] = ego_future[:, 6]    # Presence\n",
    "\n",
    "        return (\n",
    "            torch.tensor(X, dtype=torch.float32),\n",
    "            # torch.tensor(Y, dtype=torch.float32),\n",
    "            torch.tensor(origin, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c38f2a60-8c1f-4778-a55c-9816a674b74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.16906469e+03,  1.68248551e+03,  5.46145515e+00, -5.85380650e+00,\n",
       "        -8.22467566e-01,  0.00000000e+00]),\n",
       " array([ 3.16959927e+03,  1.68191109e+03,  5.35655550e+00, -5.75120145e+00,\n",
       "        -8.22600550e-01,  0.00000000e+00]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData[1, 0, 49, :], trainData[1, 0, 50, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3e692ea1-fc7d-483c-a4eb-f37014d8bbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0000,  0.0000,  0.8006,  0.0019,  0.0000,  0.0000,  1.0000,  0.8006,\n",
       "          0.0000,  0.8294, -0.0571,  1.0000,  1.0000,  0.0016]),\n",
       " tensor([7.8468e-02, 9.1270e-05, 1.0000e+00]),\n",
       " torch.Size([6]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = WindowedNormalizedDataset(trainData)\n",
    "X, Y, origin = data.__getitem__(1)\n",
    "X[0, 49, :], Y[0, :], origin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f4d97904-d868-4389-ae90-ac347a290da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = denormalize_ego(Y[0, :2], origin)\n",
    "# x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "65a25669-bf13-4e59-aaf1-27a3b6246907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_ego_batch(predicted, origin, scale=10.0):\n",
    "    \"\"\"\n",
    "    Convert batch of normalized (and scaled) ego predictions back to global coordinates.\n",
    "\n",
    "    predicted: (B, ..., 2) tensor of normalized [x, y] positions\n",
    "    origin: (B, 6) tensor of ego's reference state at t=49\n",
    "    Returns:\n",
    "        (B, ..., 2) tensor of global [x, y] positions\n",
    "    \"\"\"\n",
    "    tx = origin[:, 0]  # (B,)\n",
    "    ty = origin[:, 1]  # (B,)\n",
    "    theta = origin[:, 4]  # (B,)\n",
    "\n",
    "    cos_theta = torch.cos(theta)\n",
    "    sin_theta = torch.sin(theta)\n",
    "\n",
    "    # Expand for broadcasting\n",
    "    while len(cos_theta.shape) < len(predicted.shape) - 1:\n",
    "        cos_theta = cos_theta.unsqueeze(1)\n",
    "        sin_theta = sin_theta.unsqueeze(1)\n",
    "        tx = tx.unsqueeze(1)\n",
    "        ty = ty.unsqueeze(1)\n",
    "\n",
    "    # Unscale before denormalizing\n",
    "    x = predicted[..., 0] * scale\n",
    "    y = predicted[..., 1] * scale\n",
    "\n",
    "    # Rotate\n",
    "    x_rot = x * cos_theta - y * sin_theta\n",
    "    y_rot = x * sin_theta + y * cos_theta\n",
    "\n",
    "    # Translate\n",
    "    x_global = x_rot + tx\n",
    "    y_global = y_rot + ty\n",
    "\n",
    "    return torch.stack([x_global, y_global], dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ff1569ab-c735-46e2-9c1d-4a61874ef9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 50, 50, 14])\n",
      "Output shape: torch.Size([1, 60, 2])\n",
      "\n",
      "Model parameters: 8,299,640\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TrajectoryTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=700, model_dim=256, num_heads=8, num_layers=6, dropout=0.1, pred_len=60, num_agents=50):\n",
    "        super().__init__()\n",
    "        self.model_dim = model_dim\n",
    "        self.pred_len = pred_len\n",
    "        self.num_agents = num_agents\n",
    "        \n",
    "        # Process each agent's full trajectory (50*7 = 350) into a single token\n",
    "        self.trajectory_encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, model_dim),\n",
    "            nn.LayerNorm(model_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(model_dim, model_dim),\n",
    "            nn.LayerNorm(model_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(model_dim, model_dim),\n",
    "            nn.LayerNorm(model_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 2-layer transformer encoder to process agent tokens\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=model_dim, \n",
    "                nhead=num_heads, \n",
    "                dropout=dropout, \n",
    "                batch_first=True\n",
    "            ),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        # Final linear layer to predict ego vehicle trajectory\n",
    "        self.output_fcpre = nn.Linear(model_dim, model_dim)  # 60*2 = 120\n",
    "        self.output_fc = nn.Linear(model_dim, pred_len * 2)  # 60*2 = 120\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, N, T, Ft = x.shape\n",
    "        \n",
    "        x = x.view(B, N, T * Ft)  # (B, 50, 350)\n",
    "        \n",
    "        # Encode each agent's trajectory into a token\n",
    "        agent_tokens = self.trajectory_encoder(x)  # (B, 50, model_dim)\n",
    "        \n",
    "        # Process all agent tokens through transformer\n",
    "        encoded_tokens = self.transformer_encoder(agent_tokens)  # (B, 50, model_dim)\n",
    "        \n",
    "        # Extract ego vehicle token (assuming agent 0 is ego)\n",
    "        ego_token = encoded_tokens[:, 0, :]  # (B, model_dim)\n",
    "        \n",
    "        # Predict ego trajectory\n",
    "        output = F.relu(self.output_fcpre(ego_token))  # (B, pred_len*2)\n",
    "\n",
    "        output = self.output_fc(output)  # (B, pred_len*2)\n",
    "        \n",
    "        # Reshape to (B, pred_len, 2)\n",
    "        output = output.view(B, self.pred_len, 2)  # (B, 60, 2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Test run\n",
    "model = TrajectoryTransformer()\n",
    "x = torch.randn(1, 50, 50, 14)  \n",
    "out = model(x)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {out.shape}\")  # Expected: (1, 60, 2)\n",
    "\n",
    "# Print model summary\n",
    "print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2aa753ec-b0a2-4151-92ed-cbcf6354b637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 8299640\n"
     ]
    }
   ],
   "source": [
    "model = TrajectoryTransformer().to(device=device)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8f7683ce-9a52-4a67-9e3a-bfe7654a508d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (9000, 50, 110, 6)\n",
      "Validation shape: (1000, 50, 110, 6)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "num_samples = trainData.shape[0]\n",
    "indices = np.random.permutation(num_samples)\n",
    "split_index = int(0.9 * num_samples)\n",
    "train_idx, val_idx = indices[:split_index], indices[split_index:]\n",
    "\n",
    "# Split the data\n",
    "train_data = trainData[train_idx]\n",
    "val_data = trainData[val_idx]\n",
    "\n",
    "print(\"Train shape:\", train_data.shape)\n",
    "print(\"Validation shape:\", val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e1575bca-4895-44db-9f5d-a28d867e37e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTensor = WindowedNormalizedDataset(train_data)\n",
    "testTensor = WindowedNormalizedDataset(val_data)\n",
    "train_dataloader = DataLoader(trainTensor, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(testTensor, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ee46fc6c-294c-4b5f-bb3c-22140c2b205e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0029425269 | train val MSE 0.0165168019 | val MAE 2.3176996000 | val MSE 1.6516812667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0025348027 | train val MSE 0.0142798762 | val MAE 2.1727116723 | val MSE 1.4279882563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/1000]: 100%|██████████| 71/71 [00:34<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0023348625 | train val MSE 0.0129534931 | val MAE 2.0769047271 | val MSE 1.2953509865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0022171857 | train val MSE 0.0137854397 | val MAE 2.1483566724 | val MSE 1.3785430230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0021941995 | train val MSE 0.0121889721 | val MAE 2.0432669837 | val MSE 1.2188989185\n",
      " model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0020661576 | train val MSE 0.0112839255 | val MAE 1.9663441908 | val MSE 1.1283926629\n",
      " model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0020865798 | train val MSE 0.0121758730 | val MAE 2.0375033021 | val MSE 1.2175879218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0020198265 | train val MSE 0.0117653533 | val MAE 2.0003164485 | val MSE 1.1765354788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0020361550 | train val MSE 0.0124446647 | val MAE 2.0664384011 | val MSE 1.2444661930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000]: 100%|██████████| 71/71 [00:35<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019722332 | train val MSE 0.0106049001 | val MAE 1.9069033768 | val MSE 1.0604904490\n",
      " model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/1000]: 100%|██████████| 71/71 [00:36<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019806324 | train val MSE 0.0127116919 | val MAE 2.0958217010 | val MSE 1.2711694874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/1000]: 100%|██████████| 71/71 [00:35<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019331989 | train val MSE 0.0140788117 | val MAE 2.2140480373 | val MSE 1.4078809433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019743287 | train val MSE 0.0136030282 | val MAE 2.1517007165 | val MSE 1.3603035975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019008753 | train val MSE 0.0106993354 | val MAE 1.9399659503 | val MSE 1.0699346634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0018884297 | train val MSE 0.0105072333 | val MAE 1.9089235291 | val MSE 1.0507247029\n",
      " model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0018814761 | train val MSE 0.0105204639 | val MAE 1.9100987911 | val MSE 1.0520462627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/1000]: 100%|██████████| 71/71 [00:35<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0018773851 | train val MSE 0.0112747150 | val MAE 1.9550358206 | val MSE 1.1274727648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0018444205 | train val MSE 0.0119352292 | val MAE 2.0434247237 | val MSE 1.1935235569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/1000]: 100%|██████████| 71/71 [00:35<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0018555013 | train val MSE 0.0104798045 | val MAE 1.9142996836 | val MSE 1.0479805134\n",
      " model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/1000]: 100%|██████████| 71/71 [00:36<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0018596046 | train val MSE 0.0119421695 | val MAE 2.0661371946 | val MSE 1.1942176698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0017850912 | train val MSE 0.0112950785 | val MAE 1.9876394998 | val MSE 1.1295085745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/1000]: 100%|██████████| 71/71 [00:34<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0017304899 | train val MSE 0.0109483944 | val MAE 1.9615234621 | val MSE 1.0948403897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/1000]: 100%|██████████| 71/71 [00:34<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0017339914 | train val MSE 0.0099548031 | val MAE 1.8753447738 | val MSE 0.9954814240\n",
      " model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/1000]: 100%|██████████| 71/71 [00:34<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0017512040 | train val MSE 0.0105982430 | val MAE 1.9143188745 | val MSE 1.0598251913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0017266043 | train val MSE 0.0098207767 | val MAE 1.8569340166 | val MSE 0.9820784796\n",
      " model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [26/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0017262176 | train val MSE 0.0101037744 | val MAE 1.8828231711 | val MSE 1.0103782518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27/1000]: 100%|██████████| 71/71 [00:34<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0017297758 | train val MSE 0.0101239692 | val MAE 1.8755007982 | val MSE 1.0123970760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [28/1000]: 100%|██████████| 71/71 [00:34<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0016893622 | train val MSE 0.0110162325 | val MAE 1.9608830623 | val MSE 1.1016234178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29/1000]: 100%|██████████| 71/71 [00:36<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0017240362 | train val MSE 0.0106920988 | val MAE 1.9413995743 | val MSE 1.0692106374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [30/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0017109432 | train val MSE 0.0101808386 | val MAE 1.8885744791 | val MSE 1.0180842094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [31/1000]: 100%|██████████| 71/71 [00:35<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0017154289 | train val MSE 0.0110509405 | val MAE 1.9703605622 | val MSE 1.1050948156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [32/1000]:   3%|▎         | 2/71 [00:01<00:42,  1.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m runningLoss = \u001b[32m0.0\u001b[39m\n\u001b[32m     25\u001b[39m loop = tqdm(train_dataloader, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meach_epoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatchX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatchY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatchX\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatchX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatchY\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatchY\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36mWindowedNormalizedDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     77\u001b[39m np.fill_diagonal(dist_matrix, np.inf)\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# Find minimum distances\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m agent_min_dists = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Update only present agents\u001b[39;00m\n\u001b[32m     83\u001b[39m min_dists[present_agents, t] = agent_min_dists\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:3302\u001b[39m, in \u001b[36mmin\u001b[39m\u001b[34m(a, axis, out, keepdims, initial, where)\u001b[39m\n\u001b[32m   3190\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_min_dispatcher)\n\u001b[32m   3191\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmin\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=np._NoValue, initial=np._NoValue,\n\u001b[32m   3192\u001b[39m         where=np._NoValue):\n\u001b[32m   3193\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3194\u001b[39m \u001b[33;03m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[32m   3195\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3300\u001b[39m \u001b[33;03m    6\u001b[39;00m\n\u001b[32m   3301\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3302\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminimum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3303\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:86\u001b[39m, in \u001b[36m_wrapreduction\u001b[39m\u001b[34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis=axis, out=out, **passkwargs)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    " # train MSE 0.0022571232 | train val MSE 0.0125668047 | val MAE 2.0903749615 | val MSE 1.2566813445\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "best_model = torch.load(\"./models/final/best_model.pt\",  map_location=torch.device('cpu'))\n",
    "model.load_state_dict(best_model)\n",
    "\n",
    "epochs = 1000\n",
    "lossFn = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-6)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.25)\n",
    "best_val_loss = 0.0125668047 #float('inf')\n",
    "best_train_loss = 0.0022571232 #float('inf')\n",
    "position_scale = 1.0\n",
    "velocity_scale = 1.0\n",
    "all_losses = {\n",
    "    'training_mse_loss':[],\n",
    "    'validation_mse_loss':[],\n",
    "    'true_mse':[],\n",
    "    'true_mae':[]\n",
    "}\n",
    "\n",
    "for each_epoch in range(epochs):\n",
    "    model.train()\n",
    "    runningLoss = 0.0\n",
    "    loop = tqdm(train_dataloader, desc=f\"Epoch [{each_epoch+1}/{epochs}]\")\n",
    "    \n",
    "    for batchX, batchY, origin in loop:\n",
    "        batchX = batchX.to(device)\n",
    "        batchY = batchY.to(device)\n",
    "        origin = origin.to(device)\n",
    "\n",
    "        \n",
    "        pred = model(batchX)  # pred shape: (B, 60, 2)\n",
    "        \n",
    "        loss = lossFn(pred[..., :2], batchY[..., :2]).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.item()        \n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_mae = 0\n",
    "    val_mse = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batchX, batchY, origin in loop:\n",
    "            batchX = batchX.to(device)\n",
    "            batchY = batchY.to(device)\n",
    "            origin = origin.to(device)\n",
    "\n",
    "            \n",
    "            pred = model(batchX)  # pred shape: (B, 60, 2)\n",
    "            \n",
    "            loss = lossFn(pred[..., :2], batchY[..., :2]).to(device)\n",
    "            unnorm_pred = denormalize_ego_batch(pred, origin)\n",
    "            unnorm_true = denormalize_ego_batch(batchY, origin)\n",
    "\n",
    "            # print(pred[..., :2].shape, batchY[..., :2].shape, origin.shape, unnorm_pred.shape)\n",
    "            \n",
    "            # break\n",
    "            \n",
    "            # unnorm_pred = denormalize_ego(pred[..., :2], origin)\n",
    "            # unnorm_true = denormalize_ego(batchY, origin)\n",
    "\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_mae += nn.L1Loss()(unnorm_pred[..., :2], unnorm_true[..., :2]).item()\n",
    "            val_mse += nn.MSELoss()(unnorm_pred[..., :2], unnorm_true[..., :2]).item()\n",
    "    # break\n",
    "    train_loss = runningLoss/len(train_dataloader)\n",
    "    val_loss /= len(val_dataloader)\n",
    "    val_mae /= len(val_dataloader)\n",
    "    val_mse /= len(val_dataloader)\n",
    "    \n",
    "    all_losses[\"training_mse_loss\"].append(train_loss)\n",
    "    all_losses[\"validation_mse_loss\"].append(val_loss)\n",
    "    all_losses[\"true_mse\"].append(val_mse)\n",
    "    all_losses[\"true_mae\"].append(val_mae)\n",
    "    \n",
    "    loop.write(f\" train MSE {train_loss:.10f} | train val MSE {val_loss:.10f} | val MAE {val_mae:.10f} | val MSE {val_mse:.10f}\")\n",
    "    scheduler.step()\n",
    "    \n",
    "    if train_loss < best_train_loss and val_loss < best_val_loss :#- 1e-3\n",
    "        best_val_loss = val_loss\n",
    "        best_train_loss = train_loss\n",
    "        no_improvement = 0\n",
    "        torch.save(model.state_dict(), \"./models/final/best_model.pt\")\n",
    "        loop.write(f\" model Saved\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "#  train MSE 0.0019722332 | train val MSE 0.0106049001 | val MAE 1.9069033768 | val MSE 1.0604904490 - 7.8\n",
    "\n",
    " #  train MSE 0.0019108728 | train val MSE 0.0105765359 | val MAE 1.9288981240 | val MSE 1.0576545876 (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "228c9a60-f253-40d5-a2b8-4333d5eb0fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = WindowedNormalizedTestDataset(testData)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "\n",
    "best_model = torch.load(\"./models/final/best_model.pt\")\n",
    "model = model = TrajectoryTransformer().to(device=device)\n",
    "# model = model = TrajectoryTransformerPlus().to(device=device)\n",
    "\n",
    "\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "pred_list = []\n",
    "with torch.no_grad():\n",
    "    for batchX, origin in test_loader:\n",
    "        batchX = batchX.to(device)\n",
    "        batchY = batchY.to(device)\n",
    "        origin = origin.to(device)\n",
    "\n",
    "        \n",
    "        pred = model(batchX)  # pred shape: (B, 60, 2)\n",
    "        \n",
    "        unnorm_pred = denormalize_ego_batch(pred[..., :2], origin)\n",
    "        # print(unnorm_pred.shape)\n",
    "        pred_list.append(unnorm_pred.cpu().numpy())\n",
    "        # print(len(pred))\n",
    "        \n",
    "\n",
    "pred_list = np.concatenate(pred_list, axis=0)  \n",
    "pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n",
    "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
    "output_df.index.name = 'index'\n",
    "output_df.to_csv('./models/modelI/testTransFormer.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f02244-c098-4112-9db2-8ab1cb03afdf",
   "metadata": {},
   "outputs": [],
   "source": [
    " # train MSE 0.0139515618 | train val MSE 0.0823020875 | val MAE 4.7103952616 | val MSE 8.2302096859 - test 9.08\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
