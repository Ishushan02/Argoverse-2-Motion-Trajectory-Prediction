{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f880c27-677b-46b0-9644-fc68d0f67528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005946f0-f957-44d1-833f-6b24c9207d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Apple GPU\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac6c9d10-944c-49bb-bced-b07c99133eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data's shape is (10000, 50, 110, 6) and Test Data's is (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "def getData(path):\n",
    "    train_file = np.load(path+\"/train.npz\")\n",
    "    train_data = train_file['data']\n",
    "    test_file = np.load(path+\"/test_input.npz\")\n",
    "    test_data = test_file['data']\n",
    "    print(f\"Training Data's shape is {train_data.shape} and Test Data's is {test_data.shape}\")\n",
    "    return train_data, test_data\n",
    "trainData, testData = getData(\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a8358d2-020a-453f-a6d0-cad96ed725c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowedNormalizedDataset(Dataset):\n",
    "    def __init__(self, data, scale=10.0):\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "        self.dt = 0.1  # Assuming fixed time step of 0.1 seconds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scene = self.data[idx].copy()\n",
    "        presence = (scene[..., 0] != 0) | (scene[..., 1] != 0)\n",
    "\n",
    "        origin = scene[0, 49].copy()\n",
    "        tx, ty, _, _, theta, _ = origin\n",
    "\n",
    "        cos_theta = np.cos(-theta)\n",
    "        sin_theta = np.sin(-theta)\n",
    "\n",
    "        # Increase feature dimension to 14 for new features\n",
    "\n",
    "        # --- Existing features (0-8) ---\n",
    "        # ... [Keep existing normalization code for positions, velocities, heading, etc.] ...\n",
    "        # normalized_scene[..., 0] to [..., 8] as original\n",
    "        normalized_scene = np.zeros((50, 110, 11), dtype=np.float32)\n",
    "\n",
    "        # --- Normalize positions ---\n",
    "        x = scene[..., 0] - tx\n",
    "        y = scene[..., 1] - ty\n",
    "        x_n = x * cos_theta - y * sin_theta\n",
    "        y_n = x * sin_theta + y * cos_theta\n",
    "        normalized_scene[..., 0] = x_n / self.scale\n",
    "        normalized_scene[..., 1] = y_n / self.scale\n",
    "\n",
    "        # --- Normalize velocities ---\n",
    "        vx = scene[..., 2]\n",
    "        vy = scene[..., 3]\n",
    "        vx_n = vx * cos_theta - vy * sin_theta\n",
    "        vy_n = vx * sin_theta + vy * cos_theta\n",
    "        normalized_scene[..., 2] = vx_n / self.scale\n",
    "        normalized_scene[..., 3] = vy_n / self.scale\n",
    "\n",
    "        # --- Heading normalization ---\n",
    "        heading = scene[..., 4]\n",
    "        normalized_heading = heading - theta\n",
    "        normalized_heading = (normalized_heading + np.pi) % (2 * np.pi) - np.pi\n",
    "        normalized_scene[..., 4] = normalized_heading\n",
    "\n",
    "        # --- agent_type (already encoded) ---\n",
    "        normalized_scene[..., 5] = scene[..., 5]  # agent_type\n",
    "\n",
    "        # --- Presence ---\n",
    "        normalized_scene[..., 6] = presence.astype(np.float32)\n",
    "\n",
    "   \n",
    "\n",
    "        # === New Feature 2: Speed ===\n",
    "        speed = np.sqrt(vx ** 2 + vy ** 2)\n",
    "        normalized_scene[..., 7] = speed / self.scale  # scale to keep consistent magnitude\n",
    "\n",
    "        # === New Feature 3: Distance to ego ===\n",
    "        ego_pos = scene[0, :, :2]  # (110, 2)\n",
    "        dist_to_ego = np.linalg.norm(scene[..., :2] - ego_pos[None, :, :], axis=-1)\n",
    "        normalized_scene[..., 8] = dist_to_ego / self.scale\n",
    "\n",
    "        # === New Feature 1: Minimum Distance to Any Agent (Dynamic Interaction) ===\n",
    "        positions = scene[..., :2]  # Original positions (50, 110, 2)\n",
    "\n",
    "        # === New Feature 2: Acceleration Magnitude (Motion Dynamics) ===\n",
    "        vx = scene[..., 2]\n",
    "        vy = scene[..., 3]\n",
    "        speed = np.sqrt(vx**2 + vy**2)\n",
    "        \n",
    "        # Compute acceleration (delta-v / delta-t)\n",
    "        accel = np.zeros_like(speed)\n",
    "        accel[:, 1:] = (speed[:, 1:] - speed[:, :-1]) / self.dt\n",
    "        accel[:, 0] = accel[:, 1]  # Handle first timestep\n",
    "        \n",
    "        normalized_scene[..., 9] = accel / (self.scale / self.dt)  # Feature index 10\n",
    "\n",
    "        # === New Feature 3: Time-to-Collision (TTC) with Ego (Critical Event Metric) ===\n",
    "        rel_speed = np.sqrt(\n",
    "            (vx - vx[0:1])**2 + \n",
    "            (vy - vy[0:1])**2\n",
    "        )\n",
    "        dist_to_ego = np.linalg.norm(\n",
    "            positions - positions[0:1], \n",
    "            axis=-1\n",
    "        )\n",
    "        \n",
    "        ttc = dist_to_ego / (rel_speed + 1e-5)  # Avoid division by zero\n",
    "        ttc = np.clip(ttc, 0, 10)  # Clip to meaningful range (0-10s)\n",
    "        normalized_scene[..., 10] = ttc / 10.0  # Feature index 11 (scaled 0-1)\n",
    "\n",
    "        # --- Masking ---\n",
    "        missing_mask = np.expand_dims(~presence, -1)\n",
    "        normalized_scene[..., :11] = np.where(missing_mask, 0, normalized_scene[..., :11])\n",
    "\n",
    "        # Inputs: first 50 timesteps\n",
    "        X = normalized_scene[:, :50, :]  # Now (50, 50, 14 features)\n",
    "\n",
    "        # Target: ego future positions and presence\n",
    "        ego_future = normalized_scene[0, 50:]\n",
    "        Y = np.zeros((60, 3), dtype=np.float32)\n",
    "        Y[:, :2] = ego_future[:, :2]\n",
    "        Y[:, 2] = ego_future[:, 6]  # presence\n",
    "\n",
    "        return (\n",
    "            torch.tensor(X, dtype=torch.float32),\n",
    "            torch.tensor(Y, dtype=torch.float32),\n",
    "            torch.tensor(origin, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81f6dee5-7d2e-471f-b58f-fd7556b08fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowedNormalizedTestDataset(Dataset):\n",
    "    def __init__(self, data, scale=10.0):\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "        self.dt = 0.1  # Assuming fixed time step of 0.1 seconds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scene = self.data[idx].copy()\n",
    "        presence = (scene[..., 0] != 0) | (scene[..., 1] != 0)\n",
    "\n",
    "        origin = scene[0, 49].copy()\n",
    "        tx, ty, _, _, theta, _ = origin\n",
    "\n",
    "        cos_theta = np.cos(-theta)\n",
    "        sin_theta = np.sin(-theta)\n",
    "\n",
    "        # Increase feature dimension to 14 for new features\n",
    "\n",
    "        # --- Existing features (0-8) ---\n",
    "        # ... [Keep existing normalization code for positions, velocities, heading, etc.] ...\n",
    "        # normalized_scene[..., 0] to [..., 8] as original\n",
    "        normalized_scene = np.zeros((50, 50, 11), dtype=np.float32)\n",
    "\n",
    "        # --- Normalize positions ---\n",
    "        x = scene[..., 0] - tx\n",
    "        y = scene[..., 1] - ty\n",
    "        x_n = x * cos_theta - y * sin_theta\n",
    "        y_n = x * sin_theta + y * cos_theta\n",
    "        normalized_scene[..., 0] = x_n / self.scale\n",
    "        normalized_scene[..., 1] = y_n / self.scale\n",
    "\n",
    "        # --- Normalize velocities ---\n",
    "        vx = scene[..., 2]\n",
    "        vy = scene[..., 3]\n",
    "        vx_n = vx * cos_theta - vy * sin_theta\n",
    "        vy_n = vx * sin_theta + vy * cos_theta\n",
    "        normalized_scene[..., 2] = vx_n / self.scale\n",
    "        normalized_scene[..., 3] = vy_n / self.scale\n",
    "\n",
    "        # --- Heading normalization ---\n",
    "        heading = scene[..., 4]\n",
    "        normalized_heading = heading - theta\n",
    "        normalized_heading = (normalized_heading + np.pi) % (2 * np.pi) - np.pi\n",
    "        normalized_scene[..., 4] = normalized_heading\n",
    "\n",
    "        # --- agent_type (already encoded) ---\n",
    "        normalized_scene[..., 5] = scene[..., 5]  # agent_type\n",
    "\n",
    "        # --- Presence ---\n",
    "        normalized_scene[..., 6] = presence.astype(np.float32)\n",
    "\n",
    "   \n",
    "\n",
    "        # === New Feature 2: Speed ===\n",
    "        speed = np.sqrt(vx ** 2 + vy ** 2)\n",
    "        normalized_scene[..., 7] = speed / self.scale  # scale to keep consistent magnitude\n",
    "\n",
    "        # === New Feature 3: Distance to ego ===\n",
    "        ego_pos = scene[0, :, :2]  # (110, 2)\n",
    "        dist_to_ego = np.linalg.norm(scene[..., :2] - ego_pos[None, :, :], axis=-1)\n",
    "        normalized_scene[..., 8] = dist_to_ego / self.scale\n",
    "\n",
    "        # === New Feature 1: Minimum Distance to Any Agent (Dynamic Interaction) ===\n",
    "        positions = scene[..., :2]  # Original positions (50, 110, 2)\n",
    "\n",
    "        # === New Feature 2: Acceleration Magnitude (Motion Dynamics) ===\n",
    "        vx = scene[..., 2]\n",
    "        vy = scene[..., 3]\n",
    "        speed = np.sqrt(vx**2 + vy**2)\n",
    "        \n",
    "        # Compute acceleration (delta-v / delta-t)\n",
    "        accel = np.zeros_like(speed)\n",
    "        accel[:, 1:] = (speed[:, 1:] - speed[:, :-1]) / self.dt\n",
    "        accel[:, 0] = accel[:, 1]  # Handle first timestep\n",
    "        \n",
    "        normalized_scene[..., 9] = accel / (self.scale / self.dt)  # Feature index 10\n",
    "\n",
    "        # === New Feature 3: Time-to-Collision (TTC) with Ego (Critical Event Metric) ===\n",
    "        rel_speed = np.sqrt(\n",
    "            (vx - vx[0:1])**2 + \n",
    "            (vy - vy[0:1])**2\n",
    "        )\n",
    "        dist_to_ego = np.linalg.norm(\n",
    "            positions - positions[0:1], \n",
    "            axis=-1\n",
    "        )\n",
    "        \n",
    "        ttc = dist_to_ego / (rel_speed + 1e-5)  # Avoid division by zero\n",
    "        ttc = np.clip(ttc, 0, 10)  # Clip to meaningful range (0-10s)\n",
    "        normalized_scene[..., 10] = ttc / 10.0  # Feature index 11 (scaled 0-1)\n",
    "\n",
    "        # --- Masking ---\n",
    "        missing_mask = np.expand_dims(~presence, -1)\n",
    "        normalized_scene[..., :11] = np.where(missing_mask, 0, normalized_scene[..., :11])\n",
    "\n",
    "        # Inputs: first 50 timesteps\n",
    "        X = normalized_scene[:, :50, :]  # Now (50, 50, 14 features)\n",
    "\n",
    "        # Target: ego future positions and presence\n",
    "        # ego_future = normalized_scene[0, 50:]\n",
    "        # Y = np.zeros((60, 3), dtype=np.float32)\n",
    "        # Y[:, :2] = ego_future[:, :2]\n",
    "        # Y[:, 2] = ego_future[:, 6]  # presence\n",
    "\n",
    "        return (\n",
    "            torch.tensor(X, dtype=torch.float32),\n",
    "            # torch.tensor(Y, dtype=torch.float32),\n",
    "            torch.tensor(origin, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a25669-bf13-4e59-aaf1-27a3b6246907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_ego_batch(predicted, origin, scale=10.0):\n",
    "    \"\"\"\n",
    "    Convert batch of normalized (and scaled) ego predictions back to global coordinates.\n",
    "\n",
    "    predicted: (B, ..., 2) tensor of normalized [x, y] positions\n",
    "    origin: (B, 6) tensor of ego's reference state at t=49\n",
    "    Returns:\n",
    "        (B, ..., 2) tensor of global [x, y] positions\n",
    "    \"\"\"\n",
    "    tx = origin[:, 0]  # (B,)\n",
    "    ty = origin[:, 1]  # (B,)\n",
    "    theta = origin[:, 4]  # (B,)\n",
    "\n",
    "    cos_theta = torch.cos(theta)\n",
    "    sin_theta = torch.sin(theta)\n",
    "\n",
    "    # Expand for broadcasting\n",
    "    while len(cos_theta.shape) < len(predicted.shape) - 1:\n",
    "        cos_theta = cos_theta.unsqueeze(1)\n",
    "        sin_theta = sin_theta.unsqueeze(1)\n",
    "        tx = tx.unsqueeze(1)\n",
    "        ty = ty.unsqueeze(1)\n",
    "\n",
    "    # Unscale before denormalizing\n",
    "    x = predicted[..., 0] * scale\n",
    "    y = predicted[..., 1] * scale\n",
    "\n",
    "    # Rotate\n",
    "    x_rot = x * cos_theta - y * sin_theta\n",
    "    y_rot = x * sin_theta + y * cos_theta\n",
    "\n",
    "    # Translate\n",
    "    x_global = x_rot + tx\n",
    "    y_global = y_rot + ty\n",
    "\n",
    "    return torch.stack([x_global, y_global], dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "443233d1-6760-46de-803a-526cb9540a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.16906469e+03,  1.68248551e+03,  5.46145515e+00, -5.85380650e+00,\n",
       "        -8.22467566e-01,  0.00000000e+00]),\n",
       " array([ 3.16959927e+03,  1.68191109e+03,  5.35655550e+00, -5.75120145e+00,\n",
       "        -8.22600550e-01,  0.00000000e+00]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData[1, 0, 49, :], trainData[1, 0, 50, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd96f5cb-6c4f-4d8e-9011-60dc615bc898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0000,  0.0000,  0.8006,  0.0019,  0.0000,  0.0000,  1.0000,  0.8006,\n",
       "          0.0000, -0.0057,  0.0000]),\n",
       " tensor([7.8468e-02, 9.1270e-05, 1.0000e+00]),\n",
       " torch.Size([6]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = WindowedNormalizedDataset(trainData)\n",
    "X, Y, origin = data.__getitem__(1)\n",
    "X[0, 49, :], Y[0, :], origin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f51bf65-dd08-4778-a8bb-e3fa981ea192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = denormalize_ego(Y[0, :2], origin)\n",
    "# x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff1569ab-c735-46e2-9c1d-4a61874ef9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 50, 50, 11])\n",
      "Output shape: torch.Size([1, 60, 2])\n",
      "\n",
      "Model parameters: 8,261,240\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TrajectoryTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=550, model_dim=256, num_heads=8, num_layers=6, dropout=0.1, pred_len=60, num_agents=50):\n",
    "        super().__init__()\n",
    "        self.model_dim = model_dim\n",
    "        self.pred_len = pred_len\n",
    "        self.num_agents = num_agents\n",
    "        \n",
    "        # Process each agent's full trajectory (50*7 = 350) into a single token\n",
    "        self.trajectory_encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, model_dim),\n",
    "            nn.LayerNorm(model_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(model_dim, model_dim),\n",
    "            nn.LayerNorm(model_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(model_dim, model_dim),\n",
    "            nn.LayerNorm(model_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 2-layer transformer encoder to process agent tokens\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=model_dim, \n",
    "                nhead=num_heads, \n",
    "                dropout=dropout, \n",
    "                batch_first=True\n",
    "            ),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        # Final linear layer to predict ego vehicle trajectory\n",
    "        self.output_fcpre = nn.Linear(model_dim, model_dim)  # 60*2 = 120\n",
    "        self.output_fc = nn.Linear(model_dim, pred_len * 2)  # 60*2 = 120\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, N, T, Ft = x.shape\n",
    "        \n",
    "        x = x.view(B, N, T * Ft)  # (B, 50, 350)\n",
    "        \n",
    "        # Encode each agent's trajectory into a token\n",
    "        agent_tokens = self.trajectory_encoder(x)  # (B, 50, model_dim)\n",
    "        \n",
    "        # Process all agent tokens through transformer\n",
    "        encoded_tokens = self.transformer_encoder(agent_tokens)  # (B, 50, model_dim)\n",
    "        \n",
    "        # Extract ego vehicle token (assuming agent 0 is ego)\n",
    "        ego_token = encoded_tokens[:, 0, :]  # (B, model_dim)\n",
    "        \n",
    "        # Predict ego trajectory\n",
    "        output = F.relu(self.output_fcpre(ego_token))  # (B, pred_len*2)\n",
    "\n",
    "        output = self.output_fc(output)  # (B, pred_len*2)\n",
    "        \n",
    "        # Reshape to (B, pred_len, 2)\n",
    "        output = output.view(B, self.pred_len, 2)  # (B, 60, 2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Test run\n",
    "model = TrajectoryTransformer()\n",
    "x = torch.randn(1, 50, 50, 11)  \n",
    "out = model(x)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {out.shape}\")  # Expected: (1, 60, 2)\n",
    "\n",
    "# Print model summary\n",
    "print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa753ec-b0a2-4151-92ed-cbcf6354b637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 8261240\n"
     ]
    }
   ],
   "source": [
    "model = TrajectoryTransformer().to(device=device)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7683ce-9a52-4a67-9e3a-bfe7654a508d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (9000, 50, 110, 6)\n",
      "Validation shape: (1000, 50, 110, 6)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "num_samples = trainData.shape[0]\n",
    "indices = np.random.permutation(num_samples)\n",
    "split_index = int(0.9 * num_samples)\n",
    "train_idx, val_idx = indices[:split_index], indices[split_index:]\n",
    "\n",
    "# Split the data\n",
    "train_data = trainData[train_idx]\n",
    "val_data = trainData[val_idx]\n",
    "\n",
    "print(\"Train shape:\", train_data.shape)\n",
    "print(\"Validation shape:\", val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1575bca-4895-44db-9f5d-a28d867e37e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTensor = WindowedNormalizedDataset(train_data)\n",
    "testTensor = WindowedNormalizedDataset(val_data)\n",
    "train_dataloader = DataLoader(trainTensor, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(testTensor, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee46fc6c-294c-4b5f-bb3c-22140c2b205e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000]: 100%|██████████| 71/71 [00:14<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019605993 | train val MSE 0.0114586571 | val MAE 2.0031304061 | val MSE 1.1458663046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/1000]: 100%|██████████| 71/71 [00:14<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0018826515 | train val MSE 0.0110427282 | val MAE 1.9634206444 | val MSE 1.1042731786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/1000]: 100%|██████████| 71/71 [00:14<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019395785 | train val MSE 0.0102164522 | val MAE 1.9065594282 | val MSE 1.0216448363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/1000]: 100%|██████████| 71/71 [00:14<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019362385 | train val MSE 0.0099142536 | val MAE 1.8647644781 | val MSE 0.9914264418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/1000]: 100%|██████████| 71/71 [00:14<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019770000 | train val MSE 0.0107770586 | val MAE 1.9564600736 | val MSE 1.0777065894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/1000]: 100%|██████████| 71/71 [00:14<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019161801 | train val MSE 0.0108993898 | val MAE 1.9494999275 | val MSE 1.0899394928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/1000]: 100%|██████████| 71/71 [00:14<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019069660 | train val MSE 0.0094254124 | val MAE 1.8160044458 | val MSE 0.9425422968\n",
      " model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/1000]: 100%|██████████| 71/71 [00:14<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019488777 | train val MSE 0.0091727249 | val MAE 1.7821982168 | val MSE 0.9172739256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/1000]: 100%|██████████| 71/71 [00:14<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019126889 | train val MSE 0.0095054461 | val MAE 1.8379012402 | val MSE 0.9505447969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000]: 100%|██████████| 71/71 [00:14<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019362621 | train val MSE 0.0098025147 | val MAE 1.8587361109 | val MSE 0.9802516857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/1000]: 100%|██████████| 71/71 [00:15<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019235733 | train val MSE 0.0101222494 | val MAE 1.8976789862 | val MSE 1.0122256661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/1000]: 100%|██████████| 71/71 [00:14<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019074698 | train val MSE 0.0095351973 | val MAE 1.8202554937 | val MSE 0.9535213392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/1000]: 100%|██████████| 71/71 [00:15<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019561650 | train val MSE 0.0102869866 | val MAE 1.9137237873 | val MSE 1.0287002223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/1000]: 100%|██████████| 71/71 [00:14<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0018794460 | train val MSE 0.0102258006 | val MAE 1.9024752099 | val MSE 1.0225816648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/1000]: 100%|██████████| 71/71 [00:14<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0018831621 | train val MSE 0.0104719165 | val MAE 1.9308475833 | val MSE 1.0471918844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/1000]: 100%|██████████| 71/71 [00:14<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0018859031 | train val MSE 0.0116039317 | val MAE 2.0087370854 | val MSE 1.1603942178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/1000]: 100%|██████████| 71/71 [00:14<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0019292644 | train val MSE 0.0092377354 | val MAE 1.8205459099 | val MSE 0.9237743113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/1000]: 100%|██████████| 71/71 [00:14<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0018939171 | train val MSE 0.0106581531 | val MAE 1.9602892883 | val MSE 1.0658166474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/1000]: 100%|██████████| 71/71 [00:14<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0018723383 | train val MSE 0.0111375353 | val MAE 1.9646999370 | val MSE 1.1137537677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/1000]: 100%|██████████| 71/71 [00:14<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0018729952 | train val MSE 0.0133672015 | val MAE 2.1369190477 | val MSE 1.3367223535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/1000]: 100%|██████████| 71/71 [00:15<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train MSE 0.0017873103 | train val MSE 0.0097348515 | val MAE 1.8597531840 | val MSE 0.9734857948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/1000]:  20%|█▉        | 14/71 [00:02<00:12,  4.67it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m runningLoss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     24\u001b[0m loop \u001b[38;5;241m=\u001b[39m tqdm(train_dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meach_epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatchX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatchY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatchX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatchX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatchY\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatchY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[4], line 82\u001b[0m, in \u001b[0;36mWindowedNormalizedDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     79\u001b[0m normalized_scene[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m9\u001b[39m] \u001b[38;5;241m=\u001b[39m accel \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt)  \u001b[38;5;66;03m# Feature index 10\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# === New Feature 3: Time-to-Collision (TTC) with Ego (Critical Event Metric) ===\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m rel_speed \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m dist_to_ego \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(\n\u001b[1;32m     87\u001b[0m     positions \u001b[38;5;241m-\u001b[39m positions[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m], \n\u001b[1;32m     88\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     89\u001b[0m )\n\u001b[1;32m     91\u001b[0m ttc \u001b[38;5;241m=\u001b[39m dist_to_ego \u001b[38;5;241m/\u001b[39m (rel_speed \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-5\u001b[39m)  \u001b[38;5;66;03m# Avoid division by zero\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    " #  train MSE 0.0019108728 | train val MSE 0.0105765359 | val MAE 1.9288981240 | val MSE 1.0576545876 (Baseline)\n",
    "best_model = torch.load(\"./models/modelI/best_model.pt\")\n",
    "model.load_state_dict(best_model)\n",
    "\n",
    "epochs = 1000\n",
    "lossFn = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-6)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.25)\n",
    "best_val_loss = 0.0105765359 #float('inf')\n",
    "best_train_loss = 0.0019108728 #float('inf')\n",
    "position_scale = 1.0\n",
    "velocity_scale = 1.0\n",
    "all_losses = {\n",
    "    'training_mse_loss':[],\n",
    "    'validation_mse_loss':[],\n",
    "    'true_mse':[],\n",
    "    'true_mae':[]\n",
    "}\n",
    "\n",
    "for each_epoch in range(epochs):\n",
    "    model.train()\n",
    "    runningLoss = 0.0\n",
    "    loop = tqdm(train_dataloader, desc=f\"Epoch [{each_epoch+1}/{epochs}]\")\n",
    "    \n",
    "    for batchX, batchY, origin in loop:\n",
    "        batchX = batchX.to(device)\n",
    "        batchY = batchY.to(device)\n",
    "        origin = origin.to(device)\n",
    "\n",
    "        \n",
    "        pred = model(batchX)  # pred shape: (B, 60, 2)\n",
    "        \n",
    "        loss = lossFn(pred[..., :2], batchY[..., :2]).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.item()        \n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_mae = 0\n",
    "    val_mse = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batchX, batchY, origin in loop:\n",
    "            batchX = batchX.to(device)\n",
    "            batchY = batchY.to(device)\n",
    "            origin = origin.to(device)\n",
    "\n",
    "            \n",
    "            pred = model(batchX)  # pred shape: (B, 60, 2)\n",
    "            \n",
    "            loss = lossFn(pred[..., :2], batchY[..., :2]).to(device)\n",
    "            unnorm_pred = denormalize_ego_batch(pred, origin)\n",
    "            unnorm_true = denormalize_ego_batch(batchY, origin)\n",
    "\n",
    "            # print(pred[..., :2].shape, batchY[..., :2].shape, origin.shape, unnorm_pred.shape)\n",
    "            \n",
    "            # break\n",
    "            \n",
    "            # unnorm_pred = denormalize_ego(pred[..., :2], origin)\n",
    "            # unnorm_true = denormalize_ego(batchY, origin)\n",
    "\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_mae += nn.L1Loss()(unnorm_pred[..., :2], unnorm_true[..., :2]).item()\n",
    "            val_mse += nn.MSELoss()(unnorm_pred[..., :2], unnorm_true[..., :2]).item()\n",
    "    # break\n",
    "    train_loss = runningLoss/len(train_dataloader)\n",
    "    val_loss /= len(val_dataloader)\n",
    "    val_mae /= len(val_dataloader)\n",
    "    val_mse /= len(val_dataloader)\n",
    "    \n",
    "    all_losses[\"training_mse_loss\"].append(train_loss)\n",
    "    all_losses[\"validation_mse_loss\"].append(val_loss)\n",
    "    all_losses[\"true_mse\"].append(val_mse)\n",
    "    all_losses[\"true_mae\"].append(val_mae)\n",
    "    \n",
    "    loop.write(f\" train MSE {train_loss:.10f} | train val MSE {val_loss:.10f} | val MAE {val_mae:.10f} | val MSE {val_mse:.10f}\")\n",
    "    scheduler.step()\n",
    "    \n",
    "    if train_loss < best_train_loss and val_loss < best_val_loss :#- 1e-3\n",
    "        best_val_loss = val_loss\n",
    "        best_train_loss = train_loss\n",
    "        no_improvement = 0\n",
    "        torch.save(model.state_dict(), \"./models/modelI/best_model.pt\")\n",
    "        loop.write(f\" model Saved\")\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "228c9a60-f253-40d5-a2b8-4333d5eb0fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    " # train MSE 0.0019069660 | train val MSE 0.0094254124 | val MAE 1.8160044458 | val MSE 0.9425422968 - 7.46\n",
    "\n",
    "test_dataset = WindowedNormalizedTestDataset(testData)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "\n",
    "best_model = torch.load(\"./models/modelI/best_model.pt\")\n",
    "model = model = TrajectoryTransformer().to(device=device)\n",
    "# model = model = TrajectoryTransformerPlus().to(device=device)\n",
    "\n",
    "\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "pred_list = []\n",
    "with torch.no_grad():\n",
    "    for batchX, origin in test_loader:\n",
    "        batchX = batchX.to(device)\n",
    "        batchY = batchY.to(device)\n",
    "        origin = origin.to(device)\n",
    "\n",
    "        \n",
    "        pred = model(batchX)  # pred shape: (B, 60, 2)\n",
    "        \n",
    "        unnorm_pred = denormalize_ego_batch(pred[..., :2], origin)\n",
    "        # print(unnorm_pred.shape)\n",
    "        pred_list.append(unnorm_pred.cpu().numpy())\n",
    "        # print(len(pred))\n",
    "        \n",
    "\n",
    "pred_list = np.concatenate(pred_list, axis=0)  \n",
    "pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n",
    "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
    "output_df.index.name = 'index'\n",
    "output_df.to_csv('./models/modelI/testTransFormer.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f02244-c098-4112-9db2-8ab1cb03afdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train MSE 0.0067906785 | train val MSE 0.0365855057 | val MAE 3.3914739154 | val MSE 3.6585507989 -- Test 8.03946\n",
    "# train MSE 0.0043151287 | train val MSE 0.0219720890 | val MAE 2.6549732704 | val MSE 2.1972093526 -- Test 7.62\n",
    "# train MSE 0.0037161494 | train val MSE 0.0218982005 | val MAE 2.6644983813 | val MSE 2.1898213290 -- Test 7.69\n",
    "# train MSE 0.0025154897 | train val MSE 0.0138957179 | val MAE 2.1490821969 | val MSE 1.3895723280 -- Test 7.54\n",
    "# train MSE 0.0024351706 | train val MSE 0.0127016097 | val MAE 2.0745492652 | val MSE 1.2701618038 -- Test 7.50\n",
    "# train MSE 0.0022985399 | train val MSE 0.0120968180 | val MAE 2.0344754625 | val MSE 1.2096826853 \n",
    "# train MSE 0.0021999973 | train val MSE 0.0113797741 | val MAE 1.9797802214 | val MSE 1.1379772136 -- Test 7.51\n",
    "# train MSE 0.0020566347 | train val MSE 0.0111485770 | val MAE 1.9614749197 | val MSE 1.1148587456 -- \n",
    "# train MSE 0.0019431473 | train val MSE 0.0106567538 | val MAE 1.9321254082 | val MSE 1.0656757262 -- Test 7.48\n",
    "# train MSE 0.0019361081 | train val MSE 0.0106566806 | val MAE 1.9310559519 | val MSE 1.0656687887 -- Test 7.47883\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
