{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa063e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6e6a18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Apple GPU\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16f90eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data's shape is (10000, 50, 110, 6) and Test Data's is (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "def getData(path):\n",
    "    train_file = np.load(path+\"/train.npz\")\n",
    "    train_data = train_file['data']\n",
    "    test_file = np.load(path+\"/test_input.npz\")\n",
    "    test_data = test_file['data']\n",
    "    print(f\"Training Data's shape is {train_data.shape} and Test Data's is {test_data.shape}\")\n",
    "    return train_data, test_data\n",
    "trainData, testData = getData(\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f3ff31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_zeros_mask = np.all(trainData == 0, axis=-1)\n",
    "zero_indices = np.argwhere(all_zeros_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5005b9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28855717"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zero_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cf0f8be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    2,    0],\n",
       "       [   0,    2,   81],\n",
       "       [   0,    2,   82],\n",
       "       ...,\n",
       "       [9999,   49,  107],\n",
       "       [9999,   49,  108],\n",
       "       [9999,   49,  109]], shape=(28855717, 3))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9cce6105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData[0, 2, 0, :], trainData[   0,    2,   81, :], trainData[9999,   49,  109, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8eae43c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28855717"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (trainData[..., 0] == 0) & (trainData[..., 1] == 0)\n",
    "indices = np.argwhere(mask)\n",
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2a4bc511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]], shape=(28855717, 3))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_indices == indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a89c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def transform_to_relative_frame(data):\n",
    "    data = np.copy(data)\n",
    "    ref_t = 49\n",
    "\n",
    "    pos_x = data[:, :, :, 0]\n",
    "    pos_y = data[:, :, :, 1]\n",
    "    vel_x = data[:, :, :, 2]\n",
    "    vel_y = data[:, :, :, 3]\n",
    "    heading = data[:, :, :, 4]\n",
    "\n",
    "    x_ref = pos_x[:, :, ref_t]\n",
    "    y_ref = pos_y[:, :, ref_t]\n",
    "    theta_ref = heading[:, :, ref_t]\n",
    "\n",
    "    x_ref_exp = x_ref[:, :, None]\n",
    "    y_ref_exp = y_ref[:, :, None]\n",
    "    theta_ref_exp = theta_ref[:, :, None]\n",
    "\n",
    "    cos_theta = np.cos(-theta_ref_exp)\n",
    "    sin_theta = np.sin(-theta_ref_exp)\n",
    "\n",
    "    dx = pos_x - x_ref_exp\n",
    "    dy = pos_y - y_ref_exp\n",
    "\n",
    "    new_x = dx * cos_theta - dy * sin_theta\n",
    "    new_y = dx * sin_theta + dy * cos_theta\n",
    "    new_vx = vel_x * cos_theta - vel_y * sin_theta\n",
    "    new_vy = vel_x * sin_theta + vel_y * cos_theta\n",
    "    new_heading = heading - theta_ref_exp\n",
    "    new_heading = (new_heading + np.pi) % (2 * np.pi) - np.pi\n",
    "\n",
    "    all_zero_timestamp_mask = np.all(data == 0, axis=-1)\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            for t in range(data.shape[2]):\n",
    "                if all_zero_timestamp_mask[i, j, t]:\n",
    "                    continue \n",
    "                data[i, j, t, 0] = new_x[i, j, t]\n",
    "                data[i, j, t, 1] = new_y[i, j, t]\n",
    "                data[i, j, t, 2] = new_vx[i, j, t]\n",
    "                data[i, j, t, 3] = new_vy[i, j, t]\n",
    "                data[i, j, t, 4] = new_heading[i, j, t]\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "43cdd195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize_from_relative_frame(transformed_data, original_data):\n",
    "    transformed_data = np.copy(transformed_data)\n",
    "    ref_t = 49\n",
    "\n",
    "    x_ref = original_data[:, :, ref_t, 0]\n",
    "    y_ref = original_data[:, :, ref_t, 1]\n",
    "    theta_ref = original_data[:, :, ref_t, 4]\n",
    "\n",
    "    x_ref_exp = x_ref[:, :, None]\n",
    "    y_ref_exp = y_ref[:, :, None]\n",
    "    theta_ref_exp = theta_ref[:, :, None]\n",
    "\n",
    "    cos_theta = np.cos(theta_ref_exp)\n",
    "    sin_theta = np.sin(theta_ref_exp)\n",
    "\n",
    "    rel_x = transformed_data[:, :, :, 0]\n",
    "    rel_y = transformed_data[:, :, :, 1]\n",
    "    rel_vx = transformed_data[:, :, :, 2]\n",
    "    rel_vy = transformed_data[:, :, :, 3]\n",
    "    rel_heading = transformed_data[:, :, :, 4]\n",
    "\n",
    "    global_x = rel_x * cos_theta - rel_y * sin_theta + x_ref_exp\n",
    "    global_y = rel_x * sin_theta + rel_y * cos_theta + y_ref_exp\n",
    "    global_vx = rel_vx * cos_theta - rel_vy * sin_theta\n",
    "    global_vy = rel_vx * sin_theta + rel_vy * cos_theta\n",
    "    global_heading = rel_heading + theta_ref_exp\n",
    "    global_heading = (global_heading + np.pi) % (2 * np.pi) - np.pi\n",
    "\n",
    "    # Mask for timestamps where all features are zero (shape: N,50,110)\n",
    "    all_zero_timestamp_mask = np.all(original_data == 0, axis=-1)\n",
    "\n",
    "    for i in range(transformed_data.shape[0]):\n",
    "        for j in range(transformed_data.shape[1]):\n",
    "            for t in range(transformed_data.shape[2]):\n",
    "                if all_zero_timestamp_mask[i, j, t]:\n",
    "                    continue  # skip untransforming this timestamp\n",
    "                transformed_data[i, j, t, 0] = global_x[i, j, t]\n",
    "                transformed_data[i, j, t, 1] = global_y[i, j, t]\n",
    "                transformed_data[i, j, t, 2] = global_vx[i, j, t]\n",
    "                transformed_data[i, j, t, 3] = global_vy[i, j, t]\n",
    "                transformed_data[i, j, t, 4] = global_heading[i, j, t]\n",
    "\n",
    "    return transformed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e3647f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 338.59322192, -672.21574762,   -5.32538052,    1.61518358,\n",
       "           2.84662927,    0.        ],\n",
       "       [ 338.06105992, -672.05375338,   -5.32538052,    1.61518358,\n",
       "           2.84649174,    0.        ],\n",
       "       [ 337.40442818, -671.85373445,  -10.68688785,    3.2413244 ,\n",
       "           2.84631882,    0.        ],\n",
       "       [ 336.62778653, -671.6169553 ,  -10.62519386,    3.24042872,\n",
       "           2.84611797,    0.        ],\n",
       "       [ 335.73981124, -671.34594719,  -10.61315332,    3.2487452 ,\n",
       "           2.84590647,    0.        ]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData[0, 0, :5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "eb82e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformedData = transform_to_relative_frame(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ab9b176f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.26532783e+01, -1.14474392e-01,  5.56485288e+00,\n",
       "         3.01362068e-02,  4.93283902e-03,  0.00000000e+00],\n",
       "       [-5.20970116e+01, -1.12026513e-01,  5.56485288e+00,\n",
       "         3.01362068e-02,  4.79530686e-03,  0.00000000e+00],\n",
       "       [-5.14105975e+01, -1.09135185e-01,  1.11674571e+01,\n",
       "         6.04768544e-02,  4.62238569e-03,  0.00000000e+00],\n",
       "       [-5.05986700e+01, -1.05909909e-01,  1.11082521e+01,\n",
       "         4.31068562e-02,  4.42153067e-03,  0.00000000e+00],\n",
       "       [-4.96702661e+01, -1.02495550e-01,  1.10992058e+01,\n",
       "         3.16045334e-02,  4.21003003e-03,  0.00000000e+00]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformedData[0, 0, :5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "56e0ba10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 338.59322192, -672.21574762,   -5.32538052,    1.61518358,\n",
       "           2.84662927,    0.        ],\n",
       "       [ 338.06105992, -672.05375338,   -5.32538052,    1.61518358,\n",
       "           2.84649174,    0.        ],\n",
       "       [ 337.40442818, -671.85373445,  -10.68688785,    3.2413244 ,\n",
       "           2.84631882,    0.        ],\n",
       "       [ 336.62778653, -671.6169553 ,  -10.62519386,    3.24042872,\n",
       "           2.84611797,    0.        ],\n",
       "       [ 335.73981124, -671.34594719,  -10.61315332,    3.2487452 ,\n",
       "           2.84590647,    0.        ]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueData = unnormalize_from_relative_frame(transformedData, trainData)\n",
    "trueData[0, 0, :5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f2416baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformedData[0, 2, 0, :], transformedData[0,    2,   81, :], transformedData[9999,   49,  109, :], transformedData[0, 49, 0, :], transformedData[0, 49, 1, :], transformedData[0, 49, 49, :], transformedData[0, 49, 109, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8a68f971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData[0, 2, 0, :], trainData[0,    2,   81, :], trainData[9999,   49,  109, :], trainData[0, 49, 0, :], trainData[0, 49, 1, :], trainData[0, 49, 49, :], trainData[0, 49, 109, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8ffbc55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueData[0, 2, 0, :], trueData[0,    2,   81, :], trueData[9999,   49,  109, :], trueData[0, 49, 0, :], trueData[0, 49, 1, :], trueData[0, 49, 49, :], trueData[0, 49, 109, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20516aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 60, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "        return x\n",
    "\n",
    "class MotionTransformer(nn.Module):\n",
    "    def __init__(self, feature_dim=6, agent_count=50, past_seq_len=50, future_seq_len=60, d_model=128, nhead=8, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.agent_count = agent_count\n",
    "        self.past_seq_len = past_seq_len\n",
    "        self.future_seq_len = future_seq_len\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Input projection (flatten agents and features)\n",
    "        # Each timestamp: 50 agents * 6 features = 300\n",
    "        self.input_proj = nn.Linear(agent_count * feature_dim, d_model)\n",
    "        \n",
    "        # Positional encoding for past sequence\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len=past_seq_len)\n",
    "        \n",
    "        # Transformer Encoder for past\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # For decoder input: use zeros + positional encoding for future timestamps\n",
    "        self.future_pos_encoder = PositionalEncoding(d_model, max_len=future_seq_len)\n",
    "        \n",
    "        # Learnable query vector for decoding (one agent)\n",
    "        self.query_embed = nn.Parameter(torch.randn(1, 1, d_model))  # (1, 1, d_model)\n",
    "        \n",
    "        # Transformer Decoder\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Output projection to 6 features for future timestamps\n",
    "        self.output_proj = nn.Linear(d_model, feature_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (B, 50 agents, 50 timestamps, 6 features)\n",
    "        B, A, T, F = x.shape\n",
    "        assert A == self.agent_count and T == self.past_seq_len and F == self.feature_dim\n",
    "        \n",
    "        # Rearrange to (B, T, A*F)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous().view(B, T, A * F)  # (B, T, 300)\n",
    "        \n",
    "        # Input projection\n",
    "        x = self.input_proj(x)  # (B, T, d_model)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = self.pos_encoder(x)  # (B, T, d_model)\n",
    "        \n",
    "        # Transformer expects shape (T, B, d_model)\n",
    "        memory = self.transformer_encoder(x.permute(1, 0, 2))  # (T, B, d_model)\n",
    "        \n",
    "        # Prepare decoder input queries for future timestamps\n",
    "        # Repeat query for future timestamps\n",
    "        query = self.query_embed.repeat(self.future_seq_len, B, 1)  # (future_seq_len, B, d_model)\n",
    "        \n",
    "        # Add positional encoding for future timestamps\n",
    "        query = self.future_pos_encoder(query.permute(1, 0, 2)).permute(1, 0, 2)  # (future_seq_len, B, d_model)\n",
    "        \n",
    "        # Decode future sequence based on memory\n",
    "        output = self.transformer_decoder(tgt=query, memory=memory)  # (future_seq_len, B, d_model)\n",
    "        \n",
    "        # Project to output features\n",
    "        output = self.output_proj(output)  # (future_seq_len, B, feature_dim)\n",
    "        \n",
    "        # Rearrange to (B, 1 agent, future_seq_len, feature_dim)\n",
    "        output = output.permute(1, 0, 2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "model = MotionTransformer()\n",
    "x = torch.randn(8, 50, 50, 6)\n",
    "out = model(x)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd55bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
