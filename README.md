# ğŸš— Argoverse-2 Motion Trajectory Prediction ğŸ§ ğŸ“ˆ

Welcome to the Argoverse 2 Motion Trajectory Prediction Challenge!  
This project focuses on building accurate **motion forecasting models** using the [Argoverse 2 Motion Forecasting Dataset](https://www.argoverse.org/av2.html). You'll work with real-world driving data, pushing the limits of AI in **autonomous vehicle navigation**.

<div align="center">
  <img src="https://user-images.githubusercontent.com/placeholder/autonomous-car.png" alt="Autonomous Driving" width="600"/>
</div>

---

## ğŸ“Œ About the Challenge

In real-world driving, predicting the motion of surrounding agentsâ€”vehicles, pedestrians, and cyclistsâ€”is **critical for safe navigation**.  
This dataset includes:

- ğŸ•’ **11-second scenarios** (2s past, 9s future)
- ğŸ§­ **Centroid + heading data** in **2D bird's-eye view**
- ğŸ”„ **Sampled at 10Hz**
- ğŸš¶â€â™‚ï¸ Diverse agents with complex behaviors & interactions

### ğŸ” Objective

Build ML models that predict **future trajectories** of agents with high accuracy in complex, crowded, and unpredictable scenes.

---

## ğŸ“ Dataset Summary

| Feature         | Description                               |
|-----------------|-------------------------------------------|
| Sampling Rate   | 10Hz                                      |
| Input           | Past trajectories (50 Timestamps)         |
| Output          | Future trajectories (60 Timestamps)       |
| Agents          | Vehicles, pedestrians, cyclists           |
| Environment     | Real-world urban driving                  |

---

## ğŸ”§ Model Architectures

I explored multiple architectures from basic LSTMs to advanced encoder-decoder frameworks and many other Architectures.

---

### **ğŸ“˜ Model A**

**Architecture 1**  
- ğŸ§  LSTM (1 unit) â†’ MLP (3 layers)

**Architecture 2**  
- ğŸ§± Encoder (6-layer MLP) â†’ LSTM â†’ Decoder (6-layer MLP)

<div align="center">
  <img src="https://user-images.githubusercontent.com/placeholder/model-a.png" alt="Model A Diagram" width="600"/>
</div>

---

### **ğŸ“™ Model B**

- ğŸ” Simplified version of Model A
- ğŸ”¹ Encoder (3-layer MLP) â†’ LSTM â†’ Decoder (3-layer MLP)

---

### **ğŸ“— Model F**

- ğŸŒ€ Similar to Model A with **Skip Connections** added between MLP layers
- Better at handling information flow across the model

<div align="center">
  <img src="https://user-images.githubusercontent.com/placeholder/skip-connection.png" alt="Skip Connections" width="500"/>
</div>

---

### **ğŸ“• Model M (Final Model for Preliminary Results)**

- ğŸ Finalized architecture used in benchmarking
- Combines best practices from Models A, B, and F

---

## ğŸš€ Coming Soon

> I am actively working on implementing:
- âœ… Transformer-based architectures with attention mechanisms

---

## ğŸ’» Get Started

1. Clone the repo:
   ```bash
   git clone https://github.com/yourusername/Argoverse-2-Motion-Trajectory-Prediction.git
   cd Argoverse-2-Motion-Trajectory-Prediction
